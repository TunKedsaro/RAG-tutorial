{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51517b1c",
   "metadata": {},
   "source": [
    "### 0 Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea039f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c3230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    with open(filepath,'r',encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "def load_yaml(filepath):\n",
    "    with open(filepath,'r',encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a6237",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340df88",
   "metadata": {},
   "source": [
    "### 01 Input CVResume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1897fd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"contact_information\": {\n",
      "    \"name\": \"Surya Teja Menta\",\n",
      "    \"email\": \"-\",\n",
      "    \"phone\": \"+91 8309584461\",\n",
      "    \"linkedin\": \"-\",\n",
      "    \"jobdb_link\": \"-\",\n",
      "    \"portfolio_link\": \"suryatejamenta.co.in\"\n",
      "  },\n",
      "  \"professional_summary\": {\n",
      "    \"has_summary\": \"Yes\",\n",
      "    \"summary_points\": [\n",
      "      \"I’m Surya Teja Menta, Results-driven Senior Data Scientist with 4+ years of experience in Data Science, Machine Learning (ML), and Generative AI (GenAI).\",\n",
      "      \"Proven expertise in RAG (Retrieval-Augmented Generation), LLM fine-tuning, MLOps, and end-to-end AI solutions.\",\n",
      "      \"Strong background in data analytics, statistical modeling, AI-powered automation, and scalable AI architectures.\",\n",
      "      \"IBM Certified Professional Data Scientist with hands-on experience in LangChain, Hugging Face, OpenAI APIs, Vector Databases (ChromaDB, Pinecone), and cloud deployments (AWS, GCP).\",\n",
      "      \"Passionate about AI research, model optimization, and developing cutting-edge AI solutions.\"\n",
      "    ]\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"PBR VITS, Kavali, AP\",\n",
      "      \"degree\": \"Bachelor's Degree in Computer Science\",\n",
      "      \"dates\": \"June 2016 - May 2020\",\n",
      "      \"gpa\": \"78.3%\",\n",
      "      \"honors\": \"Participated in paper presentations and won prizes.\"\n",
      "    },\n",
      "    {\n",
      "      \"institution\": \"Narayana Junior College, Kavali, AP\",\n",
      "      \"degree\": \"HSC\",\n",
      "      \"dates\": \"June 2014 - May 2016\",\n",
      "      \"gpa\": \"92.5%\",\n",
      "      \"honors\": \"-\"\n",
      "    },\n",
      "    {\n",
      "      \"institution\": \"Kranthi EM School, Kavali, AP\",\n",
      "      \"degree\": \"SSC\",\n",
      "      \"dates\": \"June 2004 - May 2014\",\n",
      "      \"gpa\": \"87%\",\n",
      "      \"honors\": \"Participated in school dramas, sports, etc.\"\n",
      "    }\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"title\": \"Senior Data Scientist\",\n",
      "      \"company\": \"Robert Bosch\",\n",
      "      \"dates\": \"Jan 2024 - Present\",\n",
      "      \"description\": [\n",
      "        \"Designed and deployed custom YOLOv8 models for computer vision applications.\",\n",
      "        \"Built multi-modal RAG pipelines for intelligent document processing, contextual retrieval, and GenAI-powered insights.\",\n",
      "        \"Worked on Time series data for Adnoc Project.\",\n",
      "        \"Developed ML algorithms for signal processing and sensor vibration data analytics using scikit-learn, PyTorch, and TensorFlow.\",\n",
      "        \"Worked on LLM fine-tuning, prompt engineering, and efficient model inference for enterprise AI applications.\",\n",
      "        \"Integrated MLOps best practices for scalable AI pipelines, model versioning, and automated deployment.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Subject Matter Expert (Data Analyst)\",\n",
      "      \"company\": \"Tudip Technologies\",\n",
      "      \"dates\": \"Oct 2020 - Oct 2023\",\n",
      "      \"description\": [\n",
      "        \"Developed interactive analytics dashboards and data reports in Google Data Studio for content management analytics.\",\n",
      "        \"Automated text summarization & paraphrasing using NLP Transformers (BART, T5) and deployed on Google Cloud Run.\",\n",
      "        \"Built AI-powered data visualization tools to enhance real-time business intelligence and trend analysis.\",\n",
      "        \"Integrated LLM-powered chatbots with Google Sheets API to improve data accessibility across teams.\",\n",
      "        \"Recognized with the Best Team Award for highest client appreciation and impactful AI-driven automation.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": {\n",
      "    \"technical\": [\n",
      "      \"Data Science\",\n",
      "      \"Machine Learning\",\n",
      "      \"Deep Learning\",\n",
      "      \"NLP\",\n",
      "      \"Computer Vision\",\n",
      "      \"LLMs\",\n",
      "      \"LLM Fine Tuning\",\n",
      "      \"Generative AI\",\n",
      "      \"OpenCV\",\n",
      "      \"YOLOv8\",\n",
      "      \"Image Processing\",\n",
      "      \"Object Detection\",\n",
      "      \"GANs\",\n",
      "      \"Signal Processing\",\n",
      "      \"Time Series Analysis\",\n",
      "      \"Tensorflow\",\n",
      "      \"Pytorch\",\n",
      "      \"Keras\",\n",
      "      \"Langchain\",\n",
      "      \"GCP Cloud Run\",\n",
      "      \"Amazon SageMaker\",\n",
      "      \"Numpy\",\n",
      "      \"Pandas\",\n",
      "      \"Scikit-learn\",\n",
      "      \"Spacy\",\n",
      "      \"NLTK\",\n",
      "      \"Matplotlib\",\n",
      "      \"Seaborn\",\n",
      "      \"Scipy\",\n",
      "      \"Jupyter Notebooks\",\n",
      "      \"Docker\",\n",
      "      \"GitHub\",\n",
      "      \"Git\",\n",
      "      \"Google Data Studio\",\n",
      "      \"Statistics & Probability\",\n",
      "      \"Calculus\",\n",
      "      \"Mathematics\",\n",
      "      \"Linear Algebra\",\n",
      "      \"Statistical Analysis\",\n",
      "      \"Data Mining\",\n",
      "      \"Model Building\",\n",
      "      \"Model Deployment\",\n",
      "      \"Hypothesis Testing\",\n",
      "      \"Data Analytics\"\n",
      "    ],\n",
      "    \"soft_skills\": [\n",
      "      \"Analytical Thinking\",\n",
      "      \"Problem Solving\",\n",
      "      \"Collaboration\",\n",
      "      \"Communication\",\n",
      "      \"Continuous Learning\",\n",
      "      \"Adaptability\",\n",
      "      \"Time Management\"\n",
      "    ],\n",
      "    \"tools_with_levels\": [\n",
      "      {\n",
      "        \"tool\": \"Amazon SageMaker\",\n",
      "        \"level\": \"basic\"\n",
      "      }\n",
      "    ],\n",
      "    \"languages\": [\n",
      "      {\n",
      "        \"language\": \"Python\",\n",
      "        \"level\": \"-\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"SQL\",\n",
      "        \"level\": \"-\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"HTML\",\n",
      "        \"level\": \"-\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"CSS\",\n",
      "        \"level\": \"-\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'contact_information': {'name': 'Surya Teja Menta',\n",
      "  'email': '-',\n",
      "  'phone': '+91 8309584461',\n",
      "  'linkedin': '-',\n",
      "  'jobdb_link': '-',\n",
      "  'portfolio_link': 'suryatejamenta.co.in'},\n",
      " 'professional_summary': {'has_summary': 'Yes',\n",
      "  'summary_points': ['I’m Surya Teja Menta, Results-driven Senior Data Scientist with 4+ years of experience in Data Science, Machine Learning (ML), and Generative AI (GenAI).',\n",
      "   'Proven expertise in RAG (Retrieval-Augmented Generation), LLM fine-tuning, MLOps, and end-to-end AI solutions.',\n",
      "   'Strong background in data analytics, statistical modeling, AI-powered automation, and scalable AI architectures.',\n",
      "   'IBM Certified Professional Data Scientist with hands-on experience in LangChain, Hugging Face, OpenAI APIs, Vector Databases (ChromaDB, Pinecone), and cloud deployments (AWS, GCP).',\n",
      "   'Passionate about AI research, model optimization, and developing cutting-edge AI solutions.']},\n",
      " 'education': [{'institution': 'PBR VITS, Kavali, AP',\n",
      "   'degree': \"Bachelor's Degree in Computer Science\",\n",
      "   'dates': 'June 2016 - May 2020',\n",
      "   'gpa': '78.3%',\n",
      "   'honors': 'Participated in paper presentations and won prizes.'},\n",
      "  {'institution': 'Narayana Junior College, Kavali, AP',\n",
      "   'degree': 'HSC',\n",
      "   'dates': 'June 2014 - May 2016',\n",
      "   'gpa': '92.5%',\n",
      "   'honors': '-'},\n",
      "  {'institution': 'Kranthi EM School, Kavali, AP',\n",
      "   'degree': 'SSC',\n",
      "   'dates': 'June 2004 - May 2014',\n",
      "   'gpa': '87%',\n",
      "   'honors': 'Participated in school dramas, sports, etc.'}],\n",
      " 'experience': [{'title': 'Senior Data Scientist',\n",
      "   'company': 'Robert Bosch',\n",
      "   'dates': 'Jan 2024 - Present',\n",
      "   'description': ['Designed and deployed custom YOLOv8 models for computer vision applications.',\n",
      "    'Built multi-modal RAG pipelines for intelligent document processing, contextual retrieval, and GenAI-powered insights.',\n",
      "    'Worked on Time series data for Adnoc Project.',\n",
      "    'Developed ML algorithms for signal processing and sensor vibration data analytics using scikit-learn, PyTorch, and TensorFlow.',\n",
      "    'Worked on LLM fine-tuning, prompt engineering, and efficient model inference for enterprise AI applications.',\n",
      "    'Integrated MLOps best practices for scalable AI pipelines, model versioning, and automated deployment.']},\n",
      "  {'title': 'Subject Matter Expert (Data Analyst)',\n",
      "   'company': 'Tudip Technologies',\n",
      "   'dates': 'Oct 2020 - Oct 2023',\n",
      "   'description': ['Developed interactive analytics dashboards and data reports in Google Data Studio for content management analytics.',\n",
      "    'Automated text summarization & paraphrasing using NLP Transformers (BART, T5) and deployed on Google Cloud Run.',\n",
      "    'Built AI-powered data visualization tools to enhance real-time business intelligence and trend analysis.',\n",
      "    'Integrated LLM-powered chatbots with Google Sheets API to improve data accessibility across teams.',\n",
      "    'Recognized with the Best Team Award for highest client appreciation and impactful AI-driven automation.']}],\n",
      " 'skills': {'technical': ['Data Science',\n",
      "   'Machine Learning',\n",
      "   'Deep Learning',\n",
      "   'NLP',\n",
      "   'Computer Vision',\n",
      "   'LLMs',\n",
      "   'LLM Fine Tuning',\n",
      "   'Generative AI',\n",
      "   'OpenCV',\n",
      "   'YOLOv8',\n",
      "   'Image Processing',\n",
      "   'Object Detection',\n",
      "   'GANs',\n",
      "   'Signal Processing',\n",
      "   'Time Series Analysis',\n",
      "   'Tensorflow',\n",
      "   'Pytorch',\n",
      "   'Keras',\n",
      "   'Langchain',\n",
      "   'GCP Cloud Run',\n",
      "   'Amazon SageMaker',\n",
      "   'Numpy',\n",
      "   'Pandas',\n",
      "   'Scikit-learn',\n",
      "   'Spacy',\n",
      "   'NLTK',\n",
      "   'Matplotlib',\n",
      "   'Seaborn',\n",
      "   'Scipy',\n",
      "   'Jupyter Notebooks',\n",
      "   'Docker',\n",
      "   'GitHub',\n",
      "   'Git',\n",
      "   'Google Data Studio',\n",
      "   'Statistics & Probability',\n",
      "   'Calculus',\n",
      "   'Mathematics',\n",
      "   'Linear Algebra',\n",
      "   'Statistical Analysis',\n",
      "   'Data Mining',\n",
      "   'Model Building',\n",
      "   'Model Deployment',\n",
      "   'Hypothesis Testing',\n",
      "   'Data Analytics'],\n",
      "  'soft_skills': ['Analytical Thinking',\n",
      "   'Problem Solving',\n",
      "   'Collaboration',\n",
      "   'Communication',\n",
      "   'Continuous Learning',\n",
      "   'Adaptability',\n",
      "   'Time Management'],\n",
      "  'tools_with_levels': [{'tool': 'Amazon SageMaker', 'level': 'basic'}],\n",
      "  'languages': [{'language': 'Python', 'level': '-'},\n",
      "   {'language': 'SQL', 'level': '-'},\n",
      "   {'language': 'HTML', 'level': '-'},\n",
      "   {'language': 'CSS', 'level': '-'}]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resume_json = load_file(\"resume_json.txt\")\n",
    "print(resume_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134fdd51",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f026a321",
   "metadata": {},
   "source": [
    "### 02 Promptbuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034ea3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import json\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1faf46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptBuilder:\n",
    "    def __init__(self,section,criteria,cvresume):\n",
    "        self.section  = section\n",
    "        self.criteria = criteria[::-1]\n",
    "        self.cvresume = cvresume\n",
    "        with open(\"prompt.yaml\",\"r\",encoding=\"utf-8\") as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "        # print(self.config)\n",
    "    def build_response_template(self):\n",
    "        return {\n",
    "            \"section\": self.section,\n",
    "            \"scores\": {\n",
    "                c: {\"score\": 0, \"feedback\": \"\"} for c in self.criteria\n",
    "            }\n",
    "        }\n",
    "    def build(self):\n",
    "        config_role      = self.config['role']['role1']\n",
    "        config_objective = self.config['objective']['objective1']\n",
    "        config_section   = self.config['section']['section1']\n",
    "        config_expected  = self.config['expected_content'][self.section]\n",
    "        config_criteria  = \"\"\n",
    "        for item in self.criteria:\n",
    "            config_criteria = f\"- {item}\\n\" + config_criteria\n",
    "        config_scale     = self.config['scale']['score1']\n",
    "        # config_output    = self.config['output']['format1']\n",
    "        \n",
    "        prompt_role      = f\"Role :\\n{config_role}\"+\"\\n\\n\"\n",
    "        prompt_objective = f\"objectvie :\\n{config_objective}\"+\"\\n\\n\"\n",
    "        prompt_section   = f\"section :\\n{config_section}\"+\"\\n\\n\"\n",
    "        prompt_expected  = f\"expected :\\n{config_expected}\"+\"\\n\"\n",
    "        prompt_criteria  = f\"Criteria :\\n{config_criteria}\"+\"\\n\"\n",
    "        prompt_scale     = f\"Scale :\\n{config_scale}\"+\"\\n\"\n",
    "        prompt_output    = f\"output :\\n{json.dumps(self.build_response_template(), indent=2)}\"+\"\\n\\n\"\n",
    "        prompt_cvresume  = f\"CV/Resume: \\n{self.cvresume}\"+\"\\n\"\n",
    "\n",
    "        prompt = prompt_role + prompt_objective + prompt_section \\\n",
    "            + prompt_expected + prompt_criteria + prompt_scale \\\n",
    "            + prompt_output + prompt_cvresume\n",
    "        prompt = prompt.replace(\"<section_name>\",self.section)\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32b06801",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = PromptBuilder( \n",
    "    section  = \"Profile\", \n",
    "    criteria = [\"Completeness\", \"ContentQuality\"],\n",
    "    cvresume = resume_json\n",
    ")\n",
    "prompt1 = p1.build()\n",
    "# print(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "089c0ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = PromptBuilder( \n",
    "    section  = \"Summary\", \n",
    "    criteria = [\"Completeness\", \"ContentQuality\",\"Grammar\",\"Length\",\"RoleRelevance\"],\n",
    "    cvresume = resume_json\n",
    ")\n",
    "prompt2 = p2.build()\n",
    "# print(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1e3d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = PromptBuilder( \n",
    "    section  = \"Education\", \n",
    "    criteria = [\"Completeness\",\"RoleRelevance\"],\n",
    "    cvresume = resume_json\n",
    ")\n",
    "prompt3 = p3.build()\n",
    "# print(prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34c645bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = PromptBuilder( \n",
    "    section  = \"Experience\", \n",
    "    criteria = [\"Completeness\", \"ContentQuality\",\"Grammar\",\"Length\",\"RoleRelevance\"],\n",
    "    cvresume = resume_json\n",
    ")\n",
    "prompt4 = p4.build()\n",
    "# print(prompt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1ee1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "p5 = PromptBuilder( \n",
    "    section  = \"Activities\", \n",
    "    criteria = [\"Completeness\", \"ContentQuality\",\"Grammar\",\"Length\"],\n",
    "    cvresume = resume_json\n",
    ")\n",
    "prompt5 = p5.build()\n",
    "# print(prompt5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6052800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p6 = PromptBuilder( \n",
    "    section  = \"Skills\", \n",
    "    criteria = [\"Completeness\",\"Length\",\"RoleRelevance\"],\n",
    "    cvresume = resume_json\n",
    ")\n",
    "prompt6 = p6.build()\n",
    "# print(prompt6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a35e1",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8cda9",
   "metadata": {},
   "source": [
    "### 03 LLMCaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "715548bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlmCaller:\n",
    "    def __init__(self,prompt):\n",
    "        self.client = genai.Client(api_key=\"AIzaSy...\")\n",
    "        self.prompt = prompt\n",
    "    def parser(self,resp):\n",
    "        text = resp.text.strip()\n",
    "        text = re.sub(r\"^```json|```$\", \"\", text).strip()\n",
    "        data = json.loads(text)\n",
    "        return data\n",
    "    def hit(self):\n",
    "        self.resp = self.client.models.generate_content(\n",
    "            model    = \"gemini-2.5-flash\",\n",
    "            contents = self.prompt\n",
    "            )\n",
    "        data = self.parser(self.resp)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dce4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlmCaller:\n",
    "    def __init__(self):\n",
    "        self.client = genai.Client(api_key=\"AIza...\")\n",
    "    def parser(self,resp):\n",
    "        text = resp.text.strip()\n",
    "        text = re.sub(r\"^```json|```$\", \"\", text).strip()\n",
    "        data = json.loads(text)\n",
    "        return data\n",
    "    def hit(self,prompt):\n",
    "        self.prompt = prompt\n",
    "        self.resp = self.client.models.generate_content(\n",
    "            model    = \"gemini-2.5-flash\",\n",
    "            contents = self.prompt\n",
    "            )\n",
    "        data = self.parser(self.resp)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f23d7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = LlmCaller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a964d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "op1 = op.hit(prompt1)\n",
    "op2 = op.hit(prompt2)\n",
    "op3 = op.hit(prompt3)\n",
    "op4 = op.hit(prompt4)\n",
    "op5 = op.hit(prompt5)\n",
    "op6 = op.hit(prompt6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2972a562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Profile',\n",
       " 'scores': {'ContentQuality': {'score': 5,\n",
       "   'feedback': \"The content is exceptionally high quality. It clearly establishes the candidate's professional identity as a 'Results-driven Senior Data Scientist with 4+ years of experience'. Key specializations like RAG, LLM fine-tuning, MLOps, and Generative AI are prominently featured, along with relevant certifications and specific tools (LangChain, Hugging Face, AWS, GCP). The language is strong, impactful, and effectively positions the candidate as an expert in their field.\"},\n",
       "  'Completeness': {'score': 5,\n",
       "   'feedback': \"The 'Professional Summary' serves as an excellent Profile section, comprehensively covering all expected elements. It clearly states the candidate's basic professional identity and precise positioning ('Senior Data Scientist'). It effectively functions as a career direction/headline and completely avoids unnecessary personal details, focusing solely on professional qualifications and aspirations.\"}}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36ab51d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Summary',\n",
       " 'scores': {'RoleRelevance': {'score': 5,\n",
       "   'feedback': \"The summary is highly relevant, immediately identifying the candidate as a 'Results-driven Senior Data Scientist' and detailing expertise directly applicable to modern AI/ML roles, especially in Generative AI. It strongly positions the candidate for senior data science or AI engineering positions.\"},\n",
       "  'Length': {'score': 2,\n",
       "   'feedback': 'The summary is composed of 5 sentences (or bullet points that read as full sentences), which slightly exceeds the recommended 2-4 sentence length. While each sentence is impactful, condensing it slightly would improve conciseness.'},\n",
       "  'Grammar': {'score': 5,\n",
       "   'feedback': 'The grammar, spelling, and punctuation are excellent. The summary reads smoothly and professionally with no errors.'},\n",
       "  'ContentQuality': {'score': 4,\n",
       "   'feedback': \"The content is strong, providing specific technical and domain strengths (RAG, LLM fine-tuning, MLOps, LangChain, AWS, GCP). It effectively communicates a career focus on 'AI research, model optimization, and developing cutting-edge AI solutions' and establishes a value proposition as a 'Results-driven' professional. It uses industry-specific terms effectively without relying on excessive generic buzzwords.\"},\n",
       "  'Completeness': {'score': 4,\n",
       "   'feedback': 'The summary provides a good overview of experience (4+ years), clearly states technical and domain strengths, and outlines career focus/value proposition. It covers all the expected elements effectively. A slightly more explicit statement of a specific career goal or type of impact desired could push it to excellent, but it is sufficiently present.'}}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6bdf87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Education',\n",
       " 'scores': {'RoleRelevance': {'score': 4,\n",
       "   'feedback': \"The Bachelor's Degree in Computer Science is highly relevant to a Data Scientist role, providing a strong foundational background. While the inclusion of HSC and SSC details is comprehensive in terms of academic history, these entries do not directly enhance the relevance to a professional data career beyond general education.\"},\n",
       "  'Completeness': {'score': 5,\n",
       "   'feedback': 'All expected information, including Institution name, Degree & field of study, Dates attended, GPA, and honors, is comprehensively provided for each educational entry, demonstrating excellent completeness.'}}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96f3aa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Experience',\n",
       " 'scores': {'RoleRelevance': {'score': 5,\n",
       "   'feedback': 'The experience section is exceptionally relevant to a Senior Data Scientist role, showcasing strong expertise in Machine Learning, Generative AI, Computer Vision (YOLOv8), NLP, RAG pipelines, LLM fine-tuning, and MLOps. The roles and responsibilities align perfectly with the stated career objective.'},\n",
       "  'Length': {'score': 5,\n",
       "   'feedback': 'The length of the experience section is optimal. Two roles, each with 5-6 clear bullet points, provide sufficient detail to showcase significant contributions without being overly verbose. This is well-suited for an experienced professional.'},\n",
       "  'Grammar': {'score': 5,\n",
       "   'feedback': 'The grammar, spelling, and punctuation throughout the experience section are excellent. The bullet points are clear, concise, and professionally written, demonstrating strong communication skills.'},\n",
       "  'ContentQuality': {'score': 4,\n",
       "   'feedback': \"The content demonstrates strong technical skills and impressive project work (e.g., YOLOv8, multi-modal RAG, LLM fine-tuning, NLP automation). Technical tools are effectively integrated. While the 'Action → method → impact' structure is generally followed, the primary area for improvement is the lack of specific quantifiable metrics or business outcomes for most achievements. For instance, 'Designed and deployed custom YOLOv8 models' is good, but 'resulting in X% accuracy improvement' or 'reducing processing time by Y%' would elevate it to excellent. The 'Best Team Award' is a strong qualitative metric of impact, but more numerical achievements would strengthen the overall content.\"},\n",
       "  'Completeness': {'score': 4,\n",
       "   'feedback': \"The section successfully includes job titles, employers, and dates for each position. Bullet points are clear, and technical tools are extensively mentioned (YOLOv8, RAG, scikit-learn, PyTorch, TensorFlow, Google Data Studio, NLP Transformers, Google Cloud Run). The 'Action → method → impact' structure is present, but the 'impact' aspect could be significantly strengthened with more quantifiable metrics. The absence of specific numerical achievements for most bullet points prevents a perfect score.\"}}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cf4ddd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Activities',\n",
       " 'scores': {'Length': {'score': 0,\n",
       "   'feedback': \"The 'Activities' section is entirely missing from the resume. There is no dedicated section or relevant content provided.\"},\n",
       "  'Grammar': {'score': 0,\n",
       "   'feedback': \"Since there is no 'Activities' section present in the resume, grammar cannot be evaluated for this section.\"},\n",
       "  'ContentQuality': {'score': 0,\n",
       "   'feedback': \"There is no dedicated 'Activities' section. While 'Participated in paper presentations and won prizes' is mentioned under education, it is too brief and generic to be considered quality content for a dedicated activities section, and it does not meet the expectation of detailed project descriptions, competitions, or club activities with responsibilities and tools/tech.\"},\n",
       "  'Completeness': {'score': 0,\n",
       "   'feedback': \"The 'Activities' section is completely missing. The resume does not include competitions, hackathons, club activities, or project descriptions outside of the professional experience, as expected for this section.\"}}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b76a72df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Skills',\n",
       " 'scores': {'RoleRelevance': {'score': 5,\n",
       "   'feedback': 'The skills section is exceptionally relevant for a Senior Data Scientist role. It comprehensively covers essential areas like Data Science, Machine Learning, Deep Learning, NLP, Computer Vision, and Generative AI, including advanced topics like LLMs, RAG, and MLOps. Specific frameworks and tools such as TensorFlow, PyTorch, Langchain, Docker, and cloud platforms (GCP, AWS) are well-represented and directly align with the experience outlined, demonstrating a strong match for the target role.'},\n",
       "  'Length': {'score': 4,\n",
       "   'feedback': \"The length is strong and appropriate for a Senior Data Scientist with 4+ years of experience. It provides a comprehensive list of technical and soft skills without being overly verbose, allowing a recruiter to quickly grasp the candidate's extensive capabilities across various domains.\"},\n",
       "  'Completeness': {'score': 4,\n",
       "   'feedback': \"The section is very comprehensive in its technical skills, covering all expected domains (ML, DL, NLP, CV, GenAI, Cloud, Python, SQL). Soft skills are clearly listed, and the grouping/categorization is effective. Areas for minor improvement include explicitly stating proficiency levels for programming languages (currently marked as '-') and expanding the 'tools_with_levels' section, which is currently sparse. While Google Data Studio is listed, adding other common enterprise BI tools like Power BI or Tableau would further strengthen this section.\"}}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6731c",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e331f9",
   "metadata": {},
   "source": [
    "### 04 SectionScoreAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0d894f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class SectionScoreAggregator:\n",
    "    def __init__(self,llm_output:dict):\n",
    "        self.llm_output      = llm_output             # op\n",
    "        self.config          = load_yaml(\"weight.yaml\")         # config\n",
    "        self.section         = llm_output[\"section\"]  # Get section\n",
    "        self.section_weights = self.config[\"weights\"][self.section]  # config[\"weights\"][section_key][criteria]\n",
    "    def aggregate(self):\n",
    "        ddict = {}\n",
    "        total = 0.0\n",
    "        # Protect multiple mutation when we run more than one time\n",
    "        scores_copy = copy.deepcopy(self.llm_output[\"scores\"])\n",
    "        for criteria, body in scores_copy.items():\n",
    "            raw = body[\"score\"]\n",
    "            w   = self.section_weights[criteria]\n",
    "            weighted = raw / 5 * w\n",
    "            body[\"score\"] = weighted\n",
    "            ddict[criteria] = body\n",
    "            total = total + weighted\n",
    "        return {\n",
    "            \"section\": self.section,\n",
    "            \"total_score\":total,\n",
    "            \"scores\":ddict\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a365d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class SectionScoreAggregator:\n",
    "    def __init__(self):\n",
    "        self.config          = load_yaml(\"weight.yaml\")         # config\n",
    "    def aggregate(self,llm_output:dict):\n",
    "        self.llm_output      = llm_output             # op\n",
    "        self.section         = llm_output[\"section\"]  # Get section\n",
    "        self.section_weights = self.config[\"weights\"][self.section]  # config[\"weights\"][section_key][criteria]\n",
    "        ddict = {}\n",
    "        total = 0.0\n",
    "        # Protect multiple mutation when we run more than one time\n",
    "        scores_copy = copy.deepcopy(self.llm_output[\"scores\"])\n",
    "        for criteria, body in scores_copy.items():\n",
    "            raw = body[\"score\"]\n",
    "            w   = self.section_weights[criteria]\n",
    "            weighted = raw / 5 * w\n",
    "            body[\"score\"] = weighted\n",
    "            ddict[criteria] = body\n",
    "            total = total + weighted\n",
    "        return {\n",
    "            \"section\": self.section,\n",
    "            \"total_score\":total,\n",
    "            \"scores\":ddict\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2472160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = SectionScoreAggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4749dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Profile',\n",
       " 'total_score': 20.0,\n",
       " 'scores': {'ContentQuality': {'score': 10.0,\n",
       "   'feedback': \"The content is exceptionally high quality. It clearly establishes the candidate's professional identity as a 'Results-driven Senior Data Scientist with 4+ years of experience'. Key specializations like RAG, LLM fine-tuning, MLOps, and Generative AI are prominently featured, along with relevant certifications and specific tools (LangChain, Hugging Face, AWS, GCP). The language is strong, impactful, and effectively positions the candidate as an expert in their field.\"},\n",
       "  'Completeness': {'score': 10.0,\n",
       "   'feedback': \"The 'Professional Summary' serves as an excellent Profile section, comprehensively covering all expected elements. It clearly states the candidate's basic professional identity and precise positioning ('Senior Data Scientist'). It effectively functions as a career direction/headline and completely avoids unnecessary personal details, focusing solely on professional qualifications and aspirations.\"}}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = agg.aggregate(op1)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5c11c60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Summary',\n",
       " 'total_score': 40.0,\n",
       " 'scores': {'RoleRelevance': {'score': 10.0,\n",
       "   'feedback': \"The summary is highly relevant, immediately identifying the candidate as a 'Results-driven Senior Data Scientist' and detailing expertise directly applicable to modern AI/ML roles, especially in Generative AI. It strongly positions the candidate for senior data science or AI engineering positions.\"},\n",
       "  'Length': {'score': 4.0,\n",
       "   'feedback': 'The summary is composed of 5 sentences (or bullet points that read as full sentences), which slightly exceeds the recommended 2-4 sentence length. While each sentence is impactful, condensing it slightly would improve conciseness.'},\n",
       "  'Grammar': {'score': 10.0,\n",
       "   'feedback': 'The grammar, spelling, and punctuation are excellent. The summary reads smoothly and professionally with no errors.'},\n",
       "  'ContentQuality': {'score': 8.0,\n",
       "   'feedback': \"The content is strong, providing specific technical and domain strengths (RAG, LLM fine-tuning, MLOps, LangChain, AWS, GCP). It effectively communicates a career focus on 'AI research, model optimization, and developing cutting-edge AI solutions' and establishes a value proposition as a 'Results-driven' professional. It uses industry-specific terms effectively without relying on excessive generic buzzwords.\"},\n",
       "  'Completeness': {'score': 8.0,\n",
       "   'feedback': 'The summary provides a good overview of experience (4+ years), clearly states technical and domain strengths, and outlines career focus/value proposition. It covers all the expected elements effectively. A slightly more explicit statement of a specific career goal or type of impact desired could push it to excellent, but it is sufficiently present.'}}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = agg.aggregate(op2)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb252bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Education',\n",
       " 'total_score': 18.0,\n",
       " 'scores': {'RoleRelevance': {'score': 8.0,\n",
       "   'feedback': \"The Bachelor's Degree in Computer Science is highly relevant to a Data Scientist role, providing a strong foundational background. While the inclusion of HSC and SSC details is comprehensive in terms of academic history, these entries do not directly enhance the relevance to a professional data career beyond general education.\"},\n",
       "  'Completeness': {'score': 10.0,\n",
       "   'feedback': 'All expected information, including Institution name, Degree & field of study, Dates attended, GPA, and honors, is comprehensively provided for each educational entry, demonstrating excellent completeness.'}}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = agg.aggregate(op3)\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f94a169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Experience',\n",
       " 'total_score': 46.0,\n",
       " 'scores': {'RoleRelevance': {'score': 10.0,\n",
       "   'feedback': 'The experience section is exceptionally relevant to a Senior Data Scientist role, showcasing strong expertise in Machine Learning, Generative AI, Computer Vision (YOLOv8), NLP, RAG pipelines, LLM fine-tuning, and MLOps. The roles and responsibilities align perfectly with the stated career objective.'},\n",
       "  'Length': {'score': 10.0,\n",
       "   'feedback': 'The length of the experience section is optimal. Two roles, each with 5-6 clear bullet points, provide sufficient detail to showcase significant contributions without being overly verbose. This is well-suited for an experienced professional.'},\n",
       "  'Grammar': {'score': 10.0,\n",
       "   'feedback': 'The grammar, spelling, and punctuation throughout the experience section are excellent. The bullet points are clear, concise, and professionally written, demonstrating strong communication skills.'},\n",
       "  'ContentQuality': {'score': 8.0,\n",
       "   'feedback': \"The content demonstrates strong technical skills and impressive project work (e.g., YOLOv8, multi-modal RAG, LLM fine-tuning, NLP automation). Technical tools are effectively integrated. While the 'Action → method → impact' structure is generally followed, the primary area for improvement is the lack of specific quantifiable metrics or business outcomes for most achievements. For instance, 'Designed and deployed custom YOLOv8 models' is good, but 'resulting in X% accuracy improvement' or 'reducing processing time by Y%' would elevate it to excellent. The 'Best Team Award' is a strong qualitative metric of impact, but more numerical achievements would strengthen the overall content.\"},\n",
       "  'Completeness': {'score': 8.0,\n",
       "   'feedback': \"The section successfully includes job titles, employers, and dates for each position. Bullet points are clear, and technical tools are extensively mentioned (YOLOv8, RAG, scikit-learn, PyTorch, TensorFlow, Google Data Studio, NLP Transformers, Google Cloud Run). The 'Action → method → impact' structure is present, but the 'impact' aspect could be significantly strengthened with more quantifiable metrics. The absence of specific numerical achievements for most bullet points prevents a perfect score.\"}}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = agg.aggregate(op4)\n",
    "s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0b7d27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Activities',\n",
       " 'total_score': 0.0,\n",
       " 'scores': {'Length': {'score': 0.0,\n",
       "   'feedback': \"The 'Activities' section is entirely missing from the resume. There is no dedicated section or relevant content provided.\"},\n",
       "  'Grammar': {'score': 0.0,\n",
       "   'feedback': \"Since there is no 'Activities' section present in the resume, grammar cannot be evaluated for this section.\"},\n",
       "  'ContentQuality': {'score': 0.0,\n",
       "   'feedback': \"There is no dedicated 'Activities' section. While 'Participated in paper presentations and won prizes' is mentioned under education, it is too brief and generic to be considered quality content for a dedicated activities section, and it does not meet the expectation of detailed project descriptions, competitions, or club activities with responsibilities and tools/tech.\"},\n",
       "  'Completeness': {'score': 0.0,\n",
       "   'feedback': \"The 'Activities' section is completely missing. The resume does not include competitions, hackathons, club activities, or project descriptions outside of the professional experience, as expected for this section.\"}}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s5 = agg.aggregate(op5)\n",
    "s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c58e2bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Skills',\n",
       " 'total_score': 26.0,\n",
       " 'scores': {'RoleRelevance': {'score': 10.0,\n",
       "   'feedback': 'The skills section is exceptionally relevant for a Senior Data Scientist role. It comprehensively covers essential areas like Data Science, Machine Learning, Deep Learning, NLP, Computer Vision, and Generative AI, including advanced topics like LLMs, RAG, and MLOps. Specific frameworks and tools such as TensorFlow, PyTorch, Langchain, Docker, and cloud platforms (GCP, AWS) are well-represented and directly align with the experience outlined, demonstrating a strong match for the target role.'},\n",
       "  'Length': {'score': 8.0,\n",
       "   'feedback': \"The length is strong and appropriate for a Senior Data Scientist with 4+ years of experience. It provides a comprehensive list of technical and soft skills without being overly verbose, allowing a recruiter to quickly grasp the candidate's extensive capabilities across various domains.\"},\n",
       "  'Completeness': {'score': 8.0,\n",
       "   'feedback': \"The section is very comprehensive in its technical skills, covering all expected domains (ML, DL, NLP, CV, GenAI, Cloud, Python, SQL). Soft skills are clearly listed, and the grouping/categorization is effective. Areas for minor improvement include explicitly stating proficiency levels for programming languages (currently marked as '-') and expanding the 'tools_with_levels' section, which is currently sparse. While Google Data Studio is listed, adding other common enterprise BI tools like Power BI or Tableau would further strengthen this section.\"}}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = agg.aggregate(op6)\n",
    "s6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad237c9",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df42fb",
   "metadata": {},
   "source": [
    "### 05 GlobalAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4763906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timezone,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bf8b6c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAggregator:\n",
    "    def __init__(self,SectionScoreAggregator_output:list):\n",
    "        self.section_outputs = SectionScoreAggregator_output\n",
    "        self.timestamp       = str(datetime.now(tz=(timezone(timedelta(hours=7)))))\n",
    "        self.model_config    = load_yaml(\"model.yaml\")     # should include model name\n",
    "        self.weight_config   = load_yaml(\"weight.yaml\")    # includes weights + version\n",
    "        self.prompt_config   = load_yaml(\"prompt.yaml\")    # includes prompt version\n",
    "    def fn1(self):\n",
    "        weights = self.weight_config[\"weights\"]\n",
    "        contribution = {}\n",
    "        total = 0.0\n",
    "        for section_data in self.section_outputs:\n",
    "            section_name    = section_data[\"section\"]\n",
    "            total_score     = section_data[\"total_score\"]\n",
    "            section_weight  = weights[section_name][\"section_weight\"]\n",
    "            section_contrib = total_score * section_weight\n",
    "            contribution[section_name] = {\n",
    "                \"section_total\": total_score,\n",
    "                \"section_weight\": section_weight,\n",
    "                \"contribution\": section_contrib\n",
    "            }\n",
    "            total = total + section_contrib\n",
    "        return {\n",
    "            \"final_resume_score\":total,\n",
    "            \"section_contribution\":contribution\n",
    "        }\n",
    "    def fn2(self):\n",
    "        details = {}\n",
    "        for section_data in self.section_outputs:\n",
    "            details[section_data[\"section\"]] = {\n",
    "                'total_score':section_data['total_score'],\n",
    "                'scores':section_data['scores']\n",
    "            }\n",
    "        return details\n",
    "    def fn3(self):\n",
    "        return {\n",
    "            \"model_name\": self.model_config['model']['generation_model'],\n",
    "            \"timestamp\": self.timestamp,\n",
    "            \"weights_version\": self.weight_config.get(\"version\", \"unknown\"),\n",
    "            \"prompt_version\": self.prompt_config.get(\"version\", \"unknown\")\n",
    "        }\n",
    "    def fn0(self):\n",
    "        conclution_part = self.fn1()\n",
    "        detail_part     = self.fn2()\n",
    "        metadata_part   = self.fn3()\n",
    "        return {\n",
    "            \"conclution\":conclution_part,\n",
    "            \"section_detail\":detail_part,\n",
    "            \"metadata\":metadata_part\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "25387e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalAggregator(\n",
    "    SectionScoreAggregator_output = [s1,s2,s3,s4,s5,s6]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a910ba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conclution': {'final_resume_score': 24.0,\n",
       "  'section_contribution': {'Profile': {'section_total': 20.0,\n",
       "    'section_weight': 0.1,\n",
       "    'contribution': 2.0},\n",
       "   'Summary': {'section_total': 40.0,\n",
       "    'section_weight': 0.1,\n",
       "    'contribution': 4.0},\n",
       "   'Education': {'section_total': 18.0,\n",
       "    'section_weight': 0.2,\n",
       "    'contribution': 3.6},\n",
       "   'Experience': {'section_total': 46.0,\n",
       "    'section_weight': 0.2,\n",
       "    'contribution': 9.200000000000001},\n",
       "   'Activities': {'section_total': 0.0,\n",
       "    'section_weight': 0.2,\n",
       "    'contribution': 0.0},\n",
       "   'Skills': {'section_total': 26.0,\n",
       "    'section_weight': 0.2,\n",
       "    'contribution': 5.2}}},\n",
       " 'section_detail': {'Profile': {'total_score': 20.0,\n",
       "   'scores': {'ContentQuality': {'score': 10.0,\n",
       "     'feedback': \"The content is exceptionally high quality. It clearly establishes the candidate's professional identity as a 'Results-driven Senior Data Scientist with 4+ years of experience'. Key specializations like RAG, LLM fine-tuning, MLOps, and Generative AI are prominently featured, along with relevant certifications and specific tools (LangChain, Hugging Face, AWS, GCP). The language is strong, impactful, and effectively positions the candidate as an expert in their field.\"},\n",
       "    'Completeness': {'score': 10.0,\n",
       "     'feedback': \"The 'Professional Summary' serves as an excellent Profile section, comprehensively covering all expected elements. It clearly states the candidate's basic professional identity and precise positioning ('Senior Data Scientist'). It effectively functions as a career direction/headline and completely avoids unnecessary personal details, focusing solely on professional qualifications and aspirations.\"}}},\n",
       "  'Summary': {'total_score': 40.0,\n",
       "   'scores': {'RoleRelevance': {'score': 10.0,\n",
       "     'feedback': \"The summary is highly relevant, immediately identifying the candidate as a 'Results-driven Senior Data Scientist' and detailing expertise directly applicable to modern AI/ML roles, especially in Generative AI. It strongly positions the candidate for senior data science or AI engineering positions.\"},\n",
       "    'Length': {'score': 4.0,\n",
       "     'feedback': 'The summary is composed of 5 sentences (or bullet points that read as full sentences), which slightly exceeds the recommended 2-4 sentence length. While each sentence is impactful, condensing it slightly would improve conciseness.'},\n",
       "    'Grammar': {'score': 10.0,\n",
       "     'feedback': 'The grammar, spelling, and punctuation are excellent. The summary reads smoothly and professionally with no errors.'},\n",
       "    'ContentQuality': {'score': 8.0,\n",
       "     'feedback': \"The content is strong, providing specific technical and domain strengths (RAG, LLM fine-tuning, MLOps, LangChain, AWS, GCP). It effectively communicates a career focus on 'AI research, model optimization, and developing cutting-edge AI solutions' and establishes a value proposition as a 'Results-driven' professional. It uses industry-specific terms effectively without relying on excessive generic buzzwords.\"},\n",
       "    'Completeness': {'score': 8.0,\n",
       "     'feedback': 'The summary provides a good overview of experience (4+ years), clearly states technical and domain strengths, and outlines career focus/value proposition. It covers all the expected elements effectively. A slightly more explicit statement of a specific career goal or type of impact desired could push it to excellent, but it is sufficiently present.'}}},\n",
       "  'Education': {'total_score': 18.0,\n",
       "   'scores': {'RoleRelevance': {'score': 8.0,\n",
       "     'feedback': \"The Bachelor's Degree in Computer Science is highly relevant to a Data Scientist role, providing a strong foundational background. While the inclusion of HSC and SSC details is comprehensive in terms of academic history, these entries do not directly enhance the relevance to a professional data career beyond general education.\"},\n",
       "    'Completeness': {'score': 10.0,\n",
       "     'feedback': 'All expected information, including Institution name, Degree & field of study, Dates attended, GPA, and honors, is comprehensively provided for each educational entry, demonstrating excellent completeness.'}}},\n",
       "  'Experience': {'total_score': 46.0,\n",
       "   'scores': {'RoleRelevance': {'score': 10.0,\n",
       "     'feedback': 'The experience section is exceptionally relevant to a Senior Data Scientist role, showcasing strong expertise in Machine Learning, Generative AI, Computer Vision (YOLOv8), NLP, RAG pipelines, LLM fine-tuning, and MLOps. The roles and responsibilities align perfectly with the stated career objective.'},\n",
       "    'Length': {'score': 10.0,\n",
       "     'feedback': 'The length of the experience section is optimal. Two roles, each with 5-6 clear bullet points, provide sufficient detail to showcase significant contributions without being overly verbose. This is well-suited for an experienced professional.'},\n",
       "    'Grammar': {'score': 10.0,\n",
       "     'feedback': 'The grammar, spelling, and punctuation throughout the experience section are excellent. The bullet points are clear, concise, and professionally written, demonstrating strong communication skills.'},\n",
       "    'ContentQuality': {'score': 8.0,\n",
       "     'feedback': \"The content demonstrates strong technical skills and impressive project work (e.g., YOLOv8, multi-modal RAG, LLM fine-tuning, NLP automation). Technical tools are effectively integrated. While the 'Action → method → impact' structure is generally followed, the primary area for improvement is the lack of specific quantifiable metrics or business outcomes for most achievements. For instance, 'Designed and deployed custom YOLOv8 models' is good, but 'resulting in X% accuracy improvement' or 'reducing processing time by Y%' would elevate it to excellent. The 'Best Team Award' is a strong qualitative metric of impact, but more numerical achievements would strengthen the overall content.\"},\n",
       "    'Completeness': {'score': 8.0,\n",
       "     'feedback': \"The section successfully includes job titles, employers, and dates for each position. Bullet points are clear, and technical tools are extensively mentioned (YOLOv8, RAG, scikit-learn, PyTorch, TensorFlow, Google Data Studio, NLP Transformers, Google Cloud Run). The 'Action → method → impact' structure is present, but the 'impact' aspect could be significantly strengthened with more quantifiable metrics. The absence of specific numerical achievements for most bullet points prevents a perfect score.\"}}},\n",
       "  'Activities': {'total_score': 0.0,\n",
       "   'scores': {'Length': {'score': 0.0,\n",
       "     'feedback': \"The 'Activities' section is entirely missing from the resume. There is no dedicated section or relevant content provided.\"},\n",
       "    'Grammar': {'score': 0.0,\n",
       "     'feedback': \"Since there is no 'Activities' section present in the resume, grammar cannot be evaluated for this section.\"},\n",
       "    'ContentQuality': {'score': 0.0,\n",
       "     'feedback': \"There is no dedicated 'Activities' section. While 'Participated in paper presentations and won prizes' is mentioned under education, it is too brief and generic to be considered quality content for a dedicated activities section, and it does not meet the expectation of detailed project descriptions, competitions, or club activities with responsibilities and tools/tech.\"},\n",
       "    'Completeness': {'score': 0.0,\n",
       "     'feedback': \"The 'Activities' section is completely missing. The resume does not include competitions, hackathons, club activities, or project descriptions outside of the professional experience, as expected for this section.\"}}},\n",
       "  'Skills': {'total_score': 26.0,\n",
       "   'scores': {'RoleRelevance': {'score': 10.0,\n",
       "     'feedback': 'The skills section is exceptionally relevant for a Senior Data Scientist role. It comprehensively covers essential areas like Data Science, Machine Learning, Deep Learning, NLP, Computer Vision, and Generative AI, including advanced topics like LLMs, RAG, and MLOps. Specific frameworks and tools such as TensorFlow, PyTorch, Langchain, Docker, and cloud platforms (GCP, AWS) are well-represented and directly align with the experience outlined, demonstrating a strong match for the target role.'},\n",
       "    'Length': {'score': 8.0,\n",
       "     'feedback': \"The length is strong and appropriate for a Senior Data Scientist with 4+ years of experience. It provides a comprehensive list of technical and soft skills without being overly verbose, allowing a recruiter to quickly grasp the candidate's extensive capabilities across various domains.\"},\n",
       "    'Completeness': {'score': 8.0,\n",
       "     'feedback': \"The section is very comprehensive in its technical skills, covering all expected domains (ML, DL, NLP, CV, GenAI, Cloud, Python, SQL). Soft skills are clearly listed, and the grouping/categorization is effective. Areas for minor improvement include explicitly stating proficiency levels for programming languages (currently marked as '-') and expanding the 'tools_with_levels' section, which is currently sparse. While Google Data Studio is listed, adding other common enterprise BI tools like Power BI or Tableau would further strengthen this section.\"}}}},\n",
       " 'metadata': {'model_name': 'gemini-2.5-flash',\n",
       "  'timestamp': '2025-12-03 22:06:01.393511+07:00',\n",
       "  'weights_version': 'weights_v1',\n",
       "  'prompt_version': 'prompt_v1'}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.fn0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0541bbf0",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0aa13a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'provider': 'google',\n",
       "  'embedding_model': 'text-embedding-004',\n",
       "  'generation_model': 'gemini-2.5-flash'}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class helperfunction():\n",
    "    def load_file(self,filepath):\n",
    "        with open(filepath,'r',encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    def load_yaml(self,filepath):\n",
    "        with open(filepath,'r',encoding=\"utf-8\") as f:\n",
    "            return yaml.safe_load(f)\n",
    "\n",
    "class A(helperfunction):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fn(self):\n",
    "        self.config = self.load_yaml(\"model.yaml\")\n",
    "        return self.config\n",
    "\n",
    "a = A()\n",
    "a.fn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
