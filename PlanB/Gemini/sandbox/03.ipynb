{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bbb761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5be47254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scale': {'scoring_scale': '0 = missing\\n1 = poor\\n2 = weak\\n3 = sufficient\\n4 = strong\\n5 = excellent'}}\n",
      "Summary\n",
      "['Completeness', 'ContentQuality', 'config_criteria']\n",
      "{'role': {'role1': 'You are the senior data science'}}\n",
      "Role :\n",
      "You are the senior data science\n",
      "objectvie :\n",
      "Evaluate the <section_name> section from the resume using the scoring criteria\n",
      "section :\n",
      "You are evaluating the <section_name> section.\n",
      "section :\n",
      "- 2-4 sentence summary of experience\n",
      "- Technical & domain strengths\n",
      "- Career focus & value proposition\n",
      "- Avoid buzzwords\n",
      "Criteria :\n",
      "- config_criteria\n",
      "- ContentQuality\n",
      "- Completeness\n",
      "\n",
      "Scale :\n",
      "0 = missing\n",
      "1 = poor\n",
      "2 = weak\n",
      "3 = sufficient\n",
      "4 = strong\n",
      "5 = excellent\n",
      "output :\n",
      "{\n",
      "  \"Score\":0,\n",
      "  \"Feedback\":\"xxx\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class PromptBuilder:\n",
    "    def __init__(self,section,criteria):\n",
    "        self.section  = section\n",
    "        self.criteria = criteria\n",
    "        with open(\"role.yaml\",\"r\",encoding=\"utf-8\") as f:\n",
    "            self.role = yaml.safe_load(f)\n",
    "        with open(\"objective.yaml\",\"r\",encoding=\"utf-8\") as f:\n",
    "            self.obj = yaml.safe_load(f)        \n",
    "        with open(\"section.yaml\",\"r\",encoding=\"utf-8\") as f:\n",
    "            self.sect = yaml.safe_load(f)        \n",
    "        with open(\"Expected.yaml\",\"r\",encoding=\"utf-8\") as f:\n",
    "            self.expt = yaml.safe_load(f)        \n",
    "        with open(\"scale.yaml\",\"r\",encoding=\"utf-8\") as f:\n",
    "            self.scal = yaml.safe_load(f)        \n",
    "        with open(\"output.yaml\",\"r\",encoding=\"utf-8\") as f:\n",
    "            self.outp = yaml.safe_load(f)\n",
    "        print(self.scal)\n",
    "\n",
    "    def build(self):\n",
    "        print(self.section)\n",
    "        print(self.criteria)\n",
    "        print(self.role)\n",
    "        role = self.role['role']['role1']\n",
    "        ojb  = self.obj['obj']['object']\n",
    "        sect = self.sect['section']['section']\n",
    "        expt = self.expt['expected_content'][self.section]\n",
    "        self.prompt_criteria = \"\"\n",
    "        for item in self.criteria:\n",
    "            self.prompt_criteria = f\"- {item}\\n\" + self.prompt_criteria\n",
    "        scal = self.scal['scale']['scoring_scale']\n",
    "        outp = self.outp['output']['default']\n",
    "        # prompt\n",
    "        prompt_role = f\"Role :\\n{role}\"+\"\\n\"\n",
    "        prompt_obj  = f\"objectvie :\\n{ojb}\"+\"\\n\"\n",
    "        prompt_sect  = f\"section :\\n{sect}\"+\"\\n\"\n",
    "        prompt_expt  = f\"section :\\n{expt}\"+\"\\n\"\n",
    "        prompt_crit  = f\"Criteria :\\n{self.prompt_criteria}\"+\"\\n\"\n",
    "        prompt_scal  = f\"Scale :\\n{scal}\"+\"\\n\"\n",
    "        prompt_outp  = f\"output :\\n{outp}\"+\"\\n\"\n",
    "\n",
    "        prompt = prompt_role + prompt_obj + prompt_sect + prompt_expt + \\\n",
    "            prompt_crit + prompt_scal + prompt_outp\n",
    "        # prompt = prompt.replace(\"<section_name>\",self.section)\n",
    "        print(prompt)\n",
    "p = PromptBuilder(\n",
    "    section = \"Summary\",\n",
    "    criteria = [\"Completeness\", \"ContentQuality\",\"config_criteria\"]\n",
    ")\n",
    "p.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c815f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptBuilder:\n",
    "    def __init__(self,section,criteria):\n",
    "        self.section  = section\n",
    "        self.criteria = criteria[::-1]\n",
    "        with open(\"prompt.yaml\",\"r\",encoding=\"utf-8\") as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "        # print(self.config)\n",
    "    def build(self):\n",
    "        config_role      = self.config['role']['role1']\n",
    "        config_objective = self.config['objective']['objective1']\n",
    "        config_section   = self.config['section']['section1']\n",
    "        config_expected  = self.config['expected_content'][self.section]\n",
    "        config_criteria  = \"\"\n",
    "        for item in self.criteria:\n",
    "            config_criteria = f\"- {item}\\n\" + config_criteria\n",
    "        config_scale     = self.config['scale']['score1']\n",
    "        config_output    = self.config['output']['format1']\n",
    "        \n",
    "        prompt_role      = f\"Role :\\n{config_role}\"+\"\\n\\n\"\n",
    "        prompt_objective = f\"objectvie :\\n{config_objective}\"+\"\\n\\n\"\n",
    "        prompt_section   = f\"section :\\n{config_section}\"+\"\\n\\n\"\n",
    "        prompt_expected  = f\"expected :\\n{config_expected}\"+\"\\n\"\n",
    "        prompt_criteria  = f\"Criteria :\\n{config_criteria}\"+\"\\n\"\n",
    "        prompt_scale     = f\"Scale :\\n{config_scale}\"+\"\\n\"\n",
    "        prompt_output    = f\"output :\\n{config_output}\"+\"\\n\"\n",
    "\n",
    "        prompt = prompt_role + prompt_objective + prompt_section \\\n",
    "            + prompt_expected + prompt_criteria + prompt_scale \\\n",
    "            + prompt_output\n",
    "        prompt = prompt.replace(\"<section_name>\",self.section)\n",
    "        print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ddb3e1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role :\n",
      "You are the expert HR evaluator\n",
      "\n",
      "objectvie :\n",
      "Evaluate the Experience section from the resume using the scoring criteria\n",
      "\n",
      "section :\n",
      "You are evaluating the Experience section.\n",
      "\n",
      "expected :\n",
      "- Job title, employer, dates\n",
      "- Clear bullet points\n",
      "- Action → method → impact structure\n",
      "- Technical tools used\n",
      "- Quantifiable metrics\n",
      "\n",
      "Criteria :\n",
      "- Completeness\n",
      "- ContentQuality\n",
      "- Length\n",
      "\n",
      "Scale :\n",
      "0 = missing\n",
      "1 = poor\n",
      "2 = weak\n",
      "3 = sufficient\n",
      "4 = strong\n",
      "5 = excellent\n",
      "\n",
      "output :\n",
      "{\n",
      "  \"Score\":0,\n",
      "  \"Feedback\":\"xxx\"\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = PromptBuilder(\n",
    "    section = \"Experience\",\n",
    "    criteria = [\"Completeness\", \"ContentQuality\",\"Length\",]\n",
    ")\n",
    "p.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b929adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role :\n",
      "You are the expert HR evaluator\n",
      "\n",
      "objectvie :\n",
      "Evaluate the Experience section from the resume using the scoring criteria\n",
      "\n",
      "section :\n",
      "You are evaluating the Experience section.\n",
      "\n",
      "expected :\n",
      "- Job title, employer, dates\n",
      "- Clear bullet points\n",
      "- Action → method → impact structure\n",
      "- Technical tools used\n",
      "- Quantifiable metrics\n",
      "\n",
      "Criteria :\n",
      "- Completeness\n",
      "- ContentQuality\n",
      "- Grammar\n",
      "- Length\n",
      "- RoleRelevance\n",
      "\n",
      "Scale :\n",
      "0 = missing\n",
      "1 = poor\n",
      "2 = weak\n",
      "3 = sufficient\n",
      "4 = strong\n",
      "5 = excellent\n",
      "\n",
      "output :\n",
      "{\n",
      "  \"Score\":0,\n",
      "  \"Feedback\":\"xxx\"\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt4 : Experience\n",
    "prompt4 = PromptBuilder( \n",
    "    section  = \"Experience\", \n",
    "    criteria = [\"Completeness\", \"ContentQuality\", \"Grammar\", \"Length\", \"RoleRelevance\"]\n",
    ")\n",
    "prompt4.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49a6231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"contact_information\": {\n",
      "    \"name\": \"Surya Teja Menta\",\n",
      "    \"email\": \"-\",\n",
      "    \"phone\": \"+91 8309584461\",\n",
      "    \"linkedin\": \"-\",\n",
      "    \"jobdb_link\": \"-\",\n",
      "    \"portfolio_link\": \"suryatejamenta.co.in\"\n",
      "  },\n",
      "  \"professional_summary\": {\n",
      "    \"has_summary\": \"Yes\",\n",
      "    \"summary_points\": [\n",
      "      \"I’m Surya Teja Menta, Results-driven Senior Data Scientist with 4+ years of experience in Data Science, Machine Learning (ML), and Generative AI (GenAI).\",\n",
      "      \"Proven expertise in RAG (Retrieval-Augmented Generation), LLM fine-tuning, MLOps, and end-to-end AI solutions.\",\n",
      "      \"Strong background in data analytics, statistical modeling, AI-powered automation, and scalable AI architectures.\",\n",
      "      \"IBM Certified Professional Data Scientist with hands-on experience in LangChain, Hugging Face, OpenAI APIs, Vector Databases (ChromaDB, Pinecone), and cloud deployments (AWS, GCP).\",\n",
      "      \"Passionate about AI research, model optimization, and developing cutting-edge AI solutions.\"\n",
      "    ]\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"PBR VITS, Kavali, AP\",\n",
      "      \"degree\": \"Bachelor's Degree in Computer Science\",\n",
      "      \"dates\": \"June 2016 - May 2020\",\n",
      "      \"gpa\": \"78.3%\",\n",
      "      \"honors\": \"Participated in paper presentations and won prizes.\"\n",
      "    },\n",
      "    {\n",
      "      \"institution\": \"Narayana Junior College, Kavali, AP\",\n",
      "      \"degree\": \"HSC\",\n",
      "      \"dates\": \"June 2014 - May 2016\",\n",
      "      \"gpa\": \"92.5%\",\n",
      "      \"honors\": \"-\"\n",
      "    },\n",
      "    {\n",
      "      \"institution\": \"Kranthi EM School, Kavali, AP\",\n",
      "      \"degree\": \"SSC\",\n",
      "      \"dates\": \"June 2004 - May 2014\",\n",
      "      \"gpa\": \"87%\",\n",
      "      \"honors\": \"Participated in school dramas, sports, etc.\"\n",
      "    }\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"title\": \"Senior Data Scientist\",\n",
      "      \"company\": \"Robert Bosch\",\n",
      "      \"dates\": \"Jan 2024 - Present\",\n",
      "      \"description\": [\n",
      "        \"Designed and deployed custom YOLOv8 models for computer vision applications.\",\n",
      "        \"Built multi-modal RAG pipelines for intelligent document processing, contextual retrieval, and GenAI-powered insights.\",\n",
      "        \"Worked on Time series data for Adnoc Project.\",\n",
      "        \"Developed ML algorithms for signal processing and sensor vibration data analytics using scikit-learn, PyTorch, and TensorFlow.\",\n",
      "        \"Worked on LLM fine-tuning, prompt engineering, and efficient model inference for enterprise AI applications.\",\n",
      "        \"Integrated MLOps best practices for scalable AI pipelines, model versioning, and automated deployment.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Subject Matter Expert (Data Analyst)\",\n",
      "      \"company\": \"Tudip Technologies\",\n",
      "      \"dates\": \"Oct 2020 - Oct 2023\",\n",
      "      \"description\": [\n",
      "        \"Developed interactive analytics dashboards and data reports in Google Data Studio for content management analytics.\",\n",
      "        \"Automated text summarization & paraphrasing using NLP Transformers (BART, T5) and deployed on Google Cloud Run.\",\n",
      "        \"Built AI-powered data visualization tools to enhance real-time business intelligence and trend analysis.\",\n",
      "        \"Integrated LLM-powered chatbots with Google Sheets API to improve data accessibility across teams.\",\n",
      "        \"Recognized with the Best Team Award for highest client appreciation and impactful AI-driven automation.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": {\n",
      "    \"technical\": [\n",
      "      \"Data Science\",\n",
      "      \"Machine Learning\",\n",
      "      \"Deep Learning\",\n",
      "      \"NLP\",\n",
      "      \"Computer Vision\",\n",
      "      \"LLMs\",\n",
      "      \"LLM Fine Tuning\",\n",
      "      \"Generative AI\",\n",
      "      \"OpenCV\",\n",
      "      \"YOLOv8\",\n",
      "      \"Image Processing\",\n",
      "      \"Object Detection\",\n",
      "      \"GANs\",\n",
      "      \"Signal Processing\",\n",
      "      \"Time Series Analysis\",\n",
      "      \"Tensorflow\",\n",
      "      \"Pytorch\",\n",
      "      \"Keras\",\n",
      "      \"Langchain\",\n",
      "      \"GCP Cloud Run\",\n",
      "      \"Amazon SageMaker\",\n",
      "      \"Numpy\",\n",
      "      \"Pandas\",\n",
      "      \"Scikit-learn\",\n",
      "      \"Spacy\",\n",
      "      \"NLTK\",\n",
      "      \"Matplotlib\",\n",
      "      \"Seaborn\",\n",
      "      \"Scipy\",\n",
      "      \"Jupyter Notebooks\",\n",
      "      \"Docker\",\n",
      "      \"GitHub\",\n",
      "      \"Git\",\n",
      "      \"Google Data Studio\",\n",
      "      \"Statistics & Probability\",\n",
      "      \"Calculus\",\n",
      "      \"Mathematics\",\n",
      "      \"Linear Algebra\",\n",
      "      \"Statistical Analysis\",\n",
      "      \"Data Mining\",\n",
      "      \"Model Building\",\n",
      "      \"Model Deployment\",\n",
      "      \"Hypothesis Testing\",\n",
      "      \"Data Analytics\"\n",
      "    ],\n",
      "    \"soft_skills\": [\n",
      "      \"Analytical Thinking\",\n",
      "      \"Problem Solving\",\n",
      "      \"Collaboration\",\n",
      "      \"Communication\",\n",
      "      \"Continuous Learning\",\n",
      "      \"Adaptability\",\n",
      "      \"Time Management\"\n",
      "    ],\n",
      "    \"tools_with_levels\": [\n",
      "      {\n",
      "        \"tool\": \"Amazon SageMaker\",\n",
      "        \"level\": \"basic\"\n",
      "      }\n",
      "    ],\n",
      "    \"languages\": [\n",
      "      {\n",
      "        \"language\": \"Python\",\n",
      "        \"level\": \"-\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"SQL\",\n",
      "        \"level\": \"-\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"HTML\",\n",
      "        \"level\": \"-\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"CSS\",\n",
      "        \"level\": \"-\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'contact_information': {'name': 'Surya Teja Menta',\n",
      "  'email': '-',\n",
      "  'phone': '+91 8309584461',\n",
      "  'linkedin': '-',\n",
      "  'jobdb_link': '-',\n",
      "  'portfolio_link': 'suryatejamenta.co.in'},\n",
      " 'professional_summary': {'has_summary': 'Yes',\n",
      "  'summary_points': ['I’m Surya Teja Menta, Results-driven Senior Data Scientist with 4+ years of experience in Data Science, Machine Learning (ML), and Generative AI (GenAI).',\n",
      "   'Proven expertise in RAG (Retrieval-Augmented Generation), LLM fine-tuning, MLOps, and end-to-end AI solutions.',\n",
      "   'Strong background in data analytics, statistical modeling, AI-powered automation, and scalable AI architectures.',\n",
      "   'IBM Certified Professional Data Scientist with hands-on experience in LangChain, Hugging Face, OpenAI APIs, Vector Databases (ChromaDB, Pinecone), and cloud deployments (AWS, GCP).',\n",
      "   'Passionate about AI research, model optimization, and developing cutting-edge AI solutions.']},\n",
      " 'education': [{'institution': 'PBR VITS, Kavali, AP',\n",
      "   'degree': \"Bachelor's Degree in Computer Science\",\n",
      "   'dates': 'June 2016 - May 2020',\n",
      "   'gpa': '78.3%',\n",
      "   'honors': 'Participated in paper presentations and won prizes.'},\n",
      "  {'institution': 'Narayana Junior College, Kavali, AP',\n",
      "   'degree': 'HSC',\n",
      "   'dates': 'June 2014 - May 2016',\n",
      "   'gpa': '92.5%',\n",
      "   'honors': '-'},\n",
      "  {'institution': 'Kranthi EM School, Kavali, AP',\n",
      "   'degree': 'SSC',\n",
      "   'dates': 'June 2004 - May 2014',\n",
      "   'gpa': '87%',\n",
      "   'honors': 'Participated in school dramas, sports, etc.'}],\n",
      " 'experience': [{'title': 'Senior Data Scientist',\n",
      "   'company': 'Robert Bosch',\n",
      "   'dates': 'Jan 2024 - Present',\n",
      "   'description': ['Designed and deployed custom YOLOv8 models for computer vision applications.',\n",
      "    'Built multi-modal RAG pipelines for intelligent document processing, contextual retrieval, and GenAI-powered insights.',\n",
      "    'Worked on Time series data for Adnoc Project.',\n",
      "    'Developed ML algorithms for signal processing and sensor vibration data analytics using scikit-learn, PyTorch, and TensorFlow.',\n",
      "    'Worked on LLM fine-tuning, prompt engineering, and efficient model inference for enterprise AI applications.',\n",
      "    'Integrated MLOps best practices for scalable AI pipelines, model versioning, and automated deployment.']},\n",
      "  {'title': 'Subject Matter Expert (Data Analyst)',\n",
      "   'company': 'Tudip Technologies',\n",
      "   'dates': 'Oct 2020 - Oct 2023',\n",
      "   'description': ['Developed interactive analytics dashboards and data reports in Google Data Studio for content management analytics.',\n",
      "    'Automated text summarization & paraphrasing using NLP Transformers (BART, T5) and deployed on Google Cloud Run.',\n",
      "    'Built AI-powered data visualization tools to enhance real-time business intelligence and trend analysis.',\n",
      "    'Integrated LLM-powered chatbots with Google Sheets API to improve data accessibility across teams.',\n",
      "    'Recognized with the Best Team Award for highest client appreciation and impactful AI-driven automation.']}],\n",
      " 'skills': {'technical': ['Data Science',\n",
      "   'Machine Learning',\n",
      "   'Deep Learning',\n",
      "   'NLP',\n",
      "   'Computer Vision',\n",
      "   'LLMs',\n",
      "   'LLM Fine Tuning',\n",
      "   'Generative AI',\n",
      "   'OpenCV',\n",
      "   'YOLOv8',\n",
      "   'Image Processing',\n",
      "   'Object Detection',\n",
      "   'GANs',\n",
      "   'Signal Processing',\n",
      "   'Time Series Analysis',\n",
      "   'Tensorflow',\n",
      "   'Pytorch',\n",
      "   'Keras',\n",
      "   'Langchain',\n",
      "   'GCP Cloud Run',\n",
      "   'Amazon SageMaker',\n",
      "   'Numpy',\n",
      "   'Pandas',\n",
      "   'Scikit-learn',\n",
      "   'Spacy',\n",
      "   'NLTK',\n",
      "   'Matplotlib',\n",
      "   'Seaborn',\n",
      "   'Scipy',\n",
      "   'Jupyter Notebooks',\n",
      "   'Docker',\n",
      "   'GitHub',\n",
      "   'Git',\n",
      "   'Google Data Studio',\n",
      "   'Statistics & Probability',\n",
      "   'Calculus',\n",
      "   'Mathematics',\n",
      "   'Linear Algebra',\n",
      "   'Statistical Analysis',\n",
      "   'Data Mining',\n",
      "   'Model Building',\n",
      "   'Model Deployment',\n",
      "   'Hypothesis Testing',\n",
      "   'Data Analytics'],\n",
      "  'soft_skills': ['Analytical Thinking',\n",
      "   'Problem Solving',\n",
      "   'Collaboration',\n",
      "   'Communication',\n",
      "   'Continuous Learning',\n",
      "   'Adaptability',\n",
      "   'Time Management'],\n",
      "  'tools_with_levels': [{'tool': 'Amazon SageMaker', 'level': 'basic'}],\n",
      "  'languages': [{'language': 'Python', 'level': '-'},\n",
      "   {'language': 'SQL', 'level': '-'},\n",
      "   {'language': 'HTML', 'level': '-'},\n",
      "   {'language': 'CSS', 'level': '-'}]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.file_loader import load_file\n",
    "\n",
    "resume_json = load_file(\"resume_json.txt\")\n",
    "print(resume_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731dcd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b30c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptBuilder:\n",
    "    def __init__(self,section,criteria,cvresume):\n",
    "        self.section  = section\n",
    "        self.criteria = criteria[::-1]\n",
    "        self.cvresume = cvresume\n",
    "        with open(\"prompt.yaml\",\"r\",encoding=\"utf-8\") as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "        # print(self.config)\n",
    "    def build(self):\n",
    "        config_role      = self.config['role']['role1']\n",
    "        config_objective = self.config['objective']['objective1']\n",
    "        config_section   = self.config['section']['section1']\n",
    "        config_expected  = self.config['expected_content'][self.section]\n",
    "        config_criteria  = \"\"\n",
    "        for item in self.criteria:\n",
    "            config_criteria = f\"- {item}\\n\" + config_criteria\n",
    "        config_scale     = self.config['scale']['score1']\n",
    "        config_output    = self.config['output']['format1']\n",
    "        \n",
    "        prompt_role      = f\"Role :\\n{config_role}\"+\"\\n\\n\"\n",
    "        prompt_objective = f\"objectvie :\\n{config_objective}\"+\"\\n\\n\"\n",
    "        prompt_section   = f\"section :\\n{config_section}\"+\"\\n\\n\"\n",
    "        prompt_expected  = f\"expected :\\n{config_expected}\"+\"\\n\"\n",
    "        prompt_criteria  = f\"Criteria :\\n{config_criteria}\"+\"\\n\"\n",
    "        prompt_scale     = f\"Scale :\\n{config_scale}\"+\"\\n\"\n",
    "        prompt_output    = f\"output :\\n{config_output}\"+\"\\n\"\n",
    "        prompt_cvresume  = f\"CV/Resume: \\n{self.cvresume}\"+\"\\n\"\n",
    "\n",
    "        prompt = prompt_role + prompt_objective + prompt_section \\\n",
    "            + prompt_expected + prompt_criteria + prompt_scale \\\n",
    "            + prompt_output + prompt_cvresume\n",
    "        prompt = prompt.replace(\"<section_name>\",self.section)\n",
    "        print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "950e4853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role :\n",
      "You are the expert HR evaluator\n",
      "\n",
      "objectvie :\n",
      "Evaluate the Experience section from the resume using the scoring criteria\n",
      "\n",
      "section :\n",
      "You are evaluating the Experience section.\n",
      "\n",
      "expected :\n",
      "- Job title, employer, dates\n",
      "- Clear bullet points\n",
      "- Action → method → impact structure\n",
      "- Technical tools used\n",
      "- Quantifiable metrics\n",
      "\n",
      "Criteria :\n",
      "- Completeness\n",
      "- ContentQuality\n",
      "- Grammar\n",
      "- Length\n",
      "- RoleRelevance\n",
      "\n",
      "Scale :\n",
      "0 = missing\n",
      "1 = poor\n",
      "2 = weak\n",
      "3 = sufficient\n",
      "4 = strong\n",
      "5 = excellent\n",
      "\n",
      "output :\n",
      "{\n",
      "  \"Score\":0,\n",
      "  \"Feedback\":\"xxx\"\n",
      "}\n",
      "\n",
      "CV/Resume: \n",
      "{\n",
      "  \"contact_information\": {\n",
      "    \"name\": \"Surya Teja Menta\",\n",
      "    \"email\": \"-\",\n",
      "    \"phone\": \"+91 8309584461\",\n",
      "    \"linkedin\": \"-\",\n",
      "    \"jobdb_link\": \"-\",\n",
      "    \"portfolio_link\": \"suryatejamenta.co.in\"\n",
      "  },\n",
      "  \"professional_summary\": {\n",
      "    \"has_summary\": \"Yes\",\n",
      "    \"summary_points\": [\n",
      "      \"I’m Surya Teja Menta, Results-driven Senior Data Scientist with 4+ years of experience in Data Science, Machine Learning (ML), and Generative AI (GenAI).\",\n",
      "      \"Proven expertise in RAG (Retrieval-Augmented Generation), LLM fine-tuning, MLOps, and end-to-end AI solutions.\",\n",
      "      \"Strong background in data analytics, statistical modeling, AI-powered automation, and scalable AI architectures.\",\n",
      "      \"IBM Certified Professional Data Scientist with hands-on experience in LangChain, Hugging Face, OpenAI APIs, Vector Databases (ChromaDB, Pinecone), and cloud deployments (AWS, GCP).\",\n",
      "      \"Passionate about AI research, model optimization, and developing cutting-edge AI solutions.\"\n",
      "    ]\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"PBR VITS, Kavali, AP\",\n",
      "      \"degree\": \"Bachelor's Degree in Computer Science\",\n",
      "      \"dates\": \"June 2016 - May 2020\",\n",
      "      \"gpa\": \"78.3%\",\n",
      "      \"honors\": \"Participated in paper presentations and won prizes.\"\n",
      "    },\n",
      "    {\n",
      "      \"institution\": \"Narayana Junior College, Kavali, AP\",\n",
      "      \"degree\": \"HSC\",\n",
      "      \"dates\": \"June 2014 - May 2016\",\n",
      "      \"gpa\": \"92.5%\",\n",
      "      \"honors\": \"-\"\n",
      "    },\n",
      "    {\n",
      "      \"institution\": \"Kranthi EM School, Kavali, AP\",\n",
      "      \"degree\": \"SSC\",\n",
      "      \"dates\": \"June 2004 - May 2014\",\n",
      "      \"gpa\": \"87%\",\n",
      "      \"honors\": \"Participated in school dramas, sports, etc.\"\n",
      "    }\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"title\": \"Senior Data Scientist\",\n",
      "      \"company\": \"Robert Bosch\",\n",
      "      \"dates\": \"Jan 2024 - Present\",\n",
      "      \"description\": [\n",
      "        \"Designed and deployed custom YOLOv8 models for computer vision applications.\",\n",
      "        \"Built multi-modal RAG pipelines for intelligent document processing, contextual retrieval, and GenAI-powered insights.\",\n",
      "        \"Worked on Time series data for Adnoc Project.\",\n",
      "        \"Developed ML algorithms for signal processing and sensor vibration data analytics using scikit-learn, PyTorch, and TensorFlow.\",\n",
      "        \"Worked on LLM fine-tuning, prompt engineering, and efficient model inference for enterprise AI applications.\",\n",
      "        \"Integrated MLOps best practices for scalable AI pipelines, model versioning, and automated deployment.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Subject Matter Expert (Data Analyst)\",\n",
      "      \"company\": \"Tudip Technologies\",\n",
      "      \"dates\": \"Oct 2020 - Oct 2023\",\n",
      "      \"description\": [\n",
      "        \"Developed interactive analytics dashboards and data reports in Google Data Studio for content management analytics.\",\n",
      "        \"Automated text summarization & paraphrasing using NLP Transformers (BART, T5) and deployed on Google Cloud Run.\",\n",
      "        \"Built AI-powered data visualization tools to enhance real-time business intelligence and trend analysis.\",\n",
      "        \"Integrated LLM-powered chatbots with Google Sheets API to improve data accessibility across teams.\",\n",
      "        \"Recognized with the Best Team Award for highest client appreciation and impactful AI-driven automation.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": {\n",
      "    \"technical\": [\n",
      "      \"Data Science\",\n",
      "      \"Machine Learning\",\n",
      "      \"Deep Learning\",\n",
      "      \"NLP\",\n",
      "      \"Computer Vision\",\n",
      "      \"LLMs\",\n",
      "      \"LLM Fine Tuning\",\n",
      "      \"Generative AI\",\n",
      "      \"OpenCV\",\n",
      "      \"YOLOv8\",\n",
      "      \"Image Processing\",\n",
      "      \"Object Detection\",\n",
      "      \"GANs\",\n",
      "      \"Signal Processing\",\n",
      "      \"Time Series Analysis\",\n",
      "      \"Tensorflow\",\n",
      "      \"Pytorch\",\n",
      "      \"Keras\",\n",
      "      \"Langchain\",\n",
      "      \"GCP Cloud Run\",\n",
      "      \"Amazon SageMaker\",\n",
      "      \"Numpy\",\n",
      "      \"Pandas\",\n",
      "      \"Scikit-learn\",\n",
      "      \"Spacy\",\n",
      "      \"NLTK\",\n",
      "      \"Matplotlib\",\n",
      "      \"Seaborn\",\n",
      "      \"Scipy\",\n",
      "      \"Jupyter Notebooks\",\n",
      "      \"Docker\",\n",
      "      \"GitHub\",\n",
      "      \"Git\",\n",
      "      \"Google Data Studio\",\n",
      "      \"Statistics & Probability\",\n",
      "      \"Calculus\",\n",
      "      \"Mathematics\",\n",
      "      \"Linear Algebra\",\n",
      "      \"Statistical Analysis\",\n",
      "      \"Data Mining\",\n",
      "      \"Model Building\",\n",
      "      \"Model Deployment\",\n",
      "      \"Hypothesis Testing\",\n",
      "      \"Data Analytics\"\n",
      "    ],\n",
      "    \"soft_skills\": [\n",
      "      \"Analytical Thinking\",\n",
      "      \"Problem Solving\",\n",
      "      \"Collaboration\",\n",
      "      \"Communication\",\n",
      "      \"Continuous Learning\",\n",
      "      \"Adaptability\",\n",
      "      \"Time Management\"\n",
      "    ],\n",
      "    \"tools_with_levels\": [\n",
      "      {\n",
      "        \"tool\": \"Amazon SageMaker\",\n",
      "        \"level\": \"basic\"\n",
      "      }\n",
      "    ],\n",
      "    \"languages\": [\n",
      "      {\n",
      "        \"language\": \"Python\",\n",
      "        \"level\": \"-\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"SQL\",\n",
      "        \"level\": \"-\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"HTML\",\n",
      "        \"level\": \"-\"\n",
      "      },\n",
      "      {\n",
      "        \"language\": \"CSS\",\n",
      "        \"level\": \"-\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n",
      "{'contact_information': {'name': 'Surya Teja Menta',\n",
      "  'email': '-',\n",
      "  'phone': '+91 8309584461',\n",
      "  'linkedin': '-',\n",
      "  'jobdb_link': '-',\n",
      "  'portfolio_link': 'suryatejamenta.co.in'},\n",
      " 'professional_summary': {'has_summary': 'Yes',\n",
      "  'summary_points': ['I’m Surya Teja Menta, Results-driven Senior Data Scientist with 4+ years of experience in Data Science, Machine Learning (ML), and Generative AI (GenAI).',\n",
      "   'Proven expertise in RAG (Retrieval-Augmented Generation), LLM fine-tuning, MLOps, and end-to-end AI solutions.',\n",
      "   'Strong background in data analytics, statistical modeling, AI-powered automation, and scalable AI architectures.',\n",
      "   'IBM Certified Professional Data Scientist with hands-on experience in LangChain, Hugging Face, OpenAI APIs, Vector Databases (ChromaDB, Pinecone), and cloud deployments (AWS, GCP).',\n",
      "   'Passionate about AI research, model optimization, and developing cutting-edge AI solutions.']},\n",
      " 'education': [{'institution': 'PBR VITS, Kavali, AP',\n",
      "   'degree': \"Bachelor's Degree in Computer Science\",\n",
      "   'dates': 'June 2016 - May 2020',\n",
      "   'gpa': '78.3%',\n",
      "   'honors': 'Participated in paper presentations and won prizes.'},\n",
      "  {'institution': 'Narayana Junior College, Kavali, AP',\n",
      "   'degree': 'HSC',\n",
      "   'dates': 'June 2014 - May 2016',\n",
      "   'gpa': '92.5%',\n",
      "   'honors': '-'},\n",
      "  {'institution': 'Kranthi EM School, Kavali, AP',\n",
      "   'degree': 'SSC',\n",
      "   'dates': 'June 2004 - May 2014',\n",
      "   'gpa': '87%',\n",
      "   'honors': 'Participated in school dramas, sports, etc.'}],\n",
      " 'experience': [{'title': 'Senior Data Scientist',\n",
      "   'company': 'Robert Bosch',\n",
      "   'dates': 'Jan 2024 - Present',\n",
      "   'description': ['Designed and deployed custom YOLOv8 models for computer vision applications.',\n",
      "    'Built multi-modal RAG pipelines for intelligent document processing, contextual retrieval, and GenAI-powered insights.',\n",
      "    'Worked on Time series data for Adnoc Project.',\n",
      "    'Developed ML algorithms for signal processing and sensor vibration data analytics using scikit-learn, PyTorch, and TensorFlow.',\n",
      "    'Worked on LLM fine-tuning, prompt engineering, and efficient model inference for enterprise AI applications.',\n",
      "    'Integrated MLOps best practices for scalable AI pipelines, model versioning, and automated deployment.']},\n",
      "  {'title': 'Subject Matter Expert (Data Analyst)',\n",
      "   'company': 'Tudip Technologies',\n",
      "   'dates': 'Oct 2020 - Oct 2023',\n",
      "   'description': ['Developed interactive analytics dashboards and data reports in Google Data Studio for content management analytics.',\n",
      "    'Automated text summarization & paraphrasing using NLP Transformers (BART, T5) and deployed on Google Cloud Run.',\n",
      "    'Built AI-powered data visualization tools to enhance real-time business intelligence and trend analysis.',\n",
      "    'Integrated LLM-powered chatbots with Google Sheets API to improve data accessibility across teams.',\n",
      "    'Recognized with the Best Team Award for highest client appreciation and impactful AI-driven automation.']}],\n",
      " 'skills': {'technical': ['Data Science',\n",
      "   'Machine Learning',\n",
      "   'Deep Learning',\n",
      "   'NLP',\n",
      "   'Computer Vision',\n",
      "   'LLMs',\n",
      "   'LLM Fine Tuning',\n",
      "   'Generative AI',\n",
      "   'OpenCV',\n",
      "   'YOLOv8',\n",
      "   'Image Processing',\n",
      "   'Object Detection',\n",
      "   'GANs',\n",
      "   'Signal Processing',\n",
      "   'Time Series Analysis',\n",
      "   'Tensorflow',\n",
      "   'Pytorch',\n",
      "   'Keras',\n",
      "   'Langchain',\n",
      "   'GCP Cloud Run',\n",
      "   'Amazon SageMaker',\n",
      "   'Numpy',\n",
      "   'Pandas',\n",
      "   'Scikit-learn',\n",
      "   'Spacy',\n",
      "   'NLTK',\n",
      "   'Matplotlib',\n",
      "   'Seaborn',\n",
      "   'Scipy',\n",
      "   'Jupyter Notebooks',\n",
      "   'Docker',\n",
      "   'GitHub',\n",
      "   'Git',\n",
      "   'Google Data Studio',\n",
      "   'Statistics & Probability',\n",
      "   'Calculus',\n",
      "   'Mathematics',\n",
      "   'Linear Algebra',\n",
      "   'Statistical Analysis',\n",
      "   'Data Mining',\n",
      "   'Model Building',\n",
      "   'Model Deployment',\n",
      "   'Hypothesis Testing',\n",
      "   'Data Analytics'],\n",
      "  'soft_skills': ['Analytical Thinking',\n",
      "   'Problem Solving',\n",
      "   'Collaboration',\n",
      "   'Communication',\n",
      "   'Continuous Learning',\n",
      "   'Adaptability',\n",
      "   'Time Management'],\n",
      "  'tools_with_levels': [{'tool': 'Amazon SageMaker', 'level': 'basic'}],\n",
      "  'languages': [{'language': 'Python', 'level': '-'},\n",
      "   {'language': 'SQL', 'level': '-'},\n",
      "   {'language': 'HTML', 'level': '-'},\n",
      "   {'language': 'CSS', 'level': '-'}]}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt4 : Experience\n",
    "prompt4 = PromptBuilder( \n",
    "    section  = \"Experience\", \n",
    "    criteria = [\"Completeness\", \"ContentQuality\", \"Grammar\", \"Length\", \"RoleRelevance\"],\n",
    "    cvresume = resume_json\n",
    ")\n",
    "prompt4.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6fe1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
