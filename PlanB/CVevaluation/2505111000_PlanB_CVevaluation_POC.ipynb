{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS5YDFcI8K94",
        "outputId": "77b1b0fc-288e-461e-b2b5-40aadb23a61e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.46.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os"
      ],
      "metadata": {
        "id": "__DdTfSu8aiy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyDWv6kjeoyOlv_Y4m_JTF0n-xoIFm8B59M\"\n",
        "# genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n"
      ],
      "metadata": {
        "id": "-4kr2D2h9DLh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6n9hW1Ke-smk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "\n",
        "client = genai.Client(api_key=\"AIzaSyDWv6kjeoyOlv_Y4m_JTF0n-xoIFm8B59M\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model    = \"gemini-2.5-flash\",\n",
        "    contents = \"Hello, how are you?\"\n",
        ")"
      ],
      "metadata": {
        "id": "KYPuq2c7-rjZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LJfz7GkN_BUY",
        "outputId": "bab90b1d-2588-4faf-f22c-57b039031fb1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello! As an AI, I don't have feelings in the way humans do, but I am functioning perfectly and ready to assist you.\\n\\nHow are you doing today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "2zJE8vGgSiaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 01"
      ],
      "metadata": {
        "id": "oOredIBee0Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvZFwEO1Sg5o",
        "outputId": "6790fe33-5f49-4696-b080-2b17a0e3643a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz"
      ],
      "metadata": {
        "id": "OvSqeMvobXlA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(file_path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "Ws-DtptlbZ52"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/01_resume_juanjosecarin.pdf\""
      ],
      "metadata": {
        "id": "ob_smNbqbZ21"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_text = extract_text_from_pdf(pdf_path)"
      ],
      "metadata": {
        "id": "AdwHMi4gbZ0Q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "XtxUzJK8b2t8",
        "outputId": "ef26ff63-322e-4c49-db94-5cb1fbacd1ce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1 of 2 \\nJuan Jose Carin \\nData Scientist \\n \\nMountain View, CA 94041 \\n \\n650-336-4590 | juanjose.carin@gmail.com \\n \\nlinkedin.com/in/juanjosecarin | \\njuanjocarin.github.io \\n \\nProfessional Profile \\nPassionate about data analysis and experiments, mainly focused on user behavior, experience, and engagement, with a solid \\nbackground in data science and statistics, and extensive experience using data insights to drive business growth. \\nEducation\\n2016 \\nUniversity of California, Berkeley \\nMaster of Information and Data Science \\nGPA: 3.93\\n \\n \\n \\nRelevant courses: \\n• Machine Learning \\n• Machine Learning at Scale \\n• Storing and Retrieving Data \\n• Field Experiments \\n• Applied Regression and Time Series \\nAnalysis \\n• Exploring and Analyzing Data \\n• Data Visualization and \\nCommunication \\n• Research Design and Applications for \\nData Analysis \\n2014 \\nUniversidad Politécnica de Madrid \\nM.S. in Statistical and Computational Information Processing \\nGPA: 3.69\\n \\n \\n \\nRelevant courses:  \\n• Data Mining \\n• Multivari'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are an expert career advisor.\n",
        "Review the following resume and give feedback in 3 sections:\n",
        "1. Summary of strengths\n",
        "2. Weaknesses or areas to improve\n",
        "3. Suggestions to make it more attractive to employers.\n",
        "\n",
        "Resume content:\n",
        "{resume_text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pZvkQDHqcBoD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "2Yx2zQSeey9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 02"
      ],
      "metadata": {
        "id": "yubyv_eje8Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model    = \"gemini-2.5-flash\",\n",
        "    contents = prompt\n",
        ")"
      ],
      "metadata": {
        "id": "cW-7mt0sdSqf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNk8SHz2dg_M",
        "outputId": "c73f7b76-e3e7-4ffd-9f0d-de37e95e8351"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerateContentResponse(\n",
              "  automatic_function_calling_history=[],\n",
              "  candidates=[\n",
              "    Candidate(\n",
              "      citation_metadata=CitationMetadata(\n",
              "        citations=[\n",
              "          Citation(\n",
              "            end_index=978,\n",
              "            license='',\n",
              "            start_index=748,\n",
              "            uri='https://www.ownteacher.com/teacher'\n",
              "          ),\n",
              "        ]\n",
              "      ),\n",
              "      content=Content(\n",
              "        parts=[\n",
              "          Part(\n",
              "            text=\"\"\"Here's a review of your resume, Juan Jose, structured into the three requested sections:\n",
              "\n",
              "---\n",
              "\n",
              "### 1. Summary of Strengths\n",
              "\n",
              "Juan Jose, your resume presents a compelling profile, especially for roles requiring a strong foundation in statistics, experimental design, and machine learning. Here are your key strengths:\n",
              "\n",
              "*   **Exceptional Educational Foundation:** Your two Master's degrees from UC Berkeley (M.I.D.S. with a 3.93 GPA) and Universidad Politécnica de Madrid demonstrate a rigorous academic background in data science, statistics, and computational information processing. The comprehensive list of relevant courses further solidifies your theoretical knowledge across various critical domains.\n",
              "*   **Robust & Diverse Technical Skillset:** You possess an impressive command of core data science languages (R, Python, SQL), big data technologies (Hadoop, Hive, Spark), and visualization tools (Tableau). Your proficiency with AWS and Git also highlights readiness for modern, cloud-based data environments.\n",
              "*   **Outstanding Practical Project Experience:** The \"Projects\" section is arguably the strongest part of your resume. It showcases a remarkable breadth and depth of hands-on experience in:\n",
              "    *   **Machine Learning & Deep Learning:** SmartCam (TensorFlow, OpenCV), Forest Cover Prediction (Scikit-Learn), Churn Prediction (Neural Networks).\n",
              "    *   **Big Data & Cloud:** Shortest Path/PageRank (Hadoop, AWS), Job Search Pipeline (Hadoop, Spark, AWS).\n",
              "    *   **Experimental Design & Statistics:** Investigating Competition Effect (Randomized Controlled Trial), Google Spain Ad Impact (matched-pair, cluster-randomized design).\n",
              "    *   **Data Engineering & Visualization:** ETL pipeline design, Citi Bike visualization.\n",
              "    This demonstrates your ability to apply complex methodologies to real-world problems and utilize a modern tech stack.\n",
              "*   **Demonstrated Business Acumen & Quantifiable Impact:** Despite being in a different field, your sales and management roles at YOKOGAWA and AYSCOM highlight crucial transferable skills. The quantified achievements (e.g., 6.3% revenue increase, 146% operating income growth, 3x new customer growth) showcase a results-oriented mindset and the ability to drive significant business outcomes, a highly valued trait in data scientists.\n",
              "*   **Strong Emphasis on Experimental Design:** Your experience in designing and executing sophisticated experiments (e.g., for Google Spain, randomized controlled trials in projects) is a significant differentiator and highly attractive for roles focused on product, growth, or causal inference.\n",
              "*   **Online Portfolio Presence:** Providing a link to your GitHub portfolio (juanjocarin.github.io) is excellent, allowing potential employers to review your code, methodologies, and project details firsthand.\n",
              "\n",
              "---\n",
              "\n",
              "### 2. Weaknesses or Areas to Improve\n",
              "\n",
              "While strong, there are several areas where your resume could be refined to maximize its impact:\n",
              "\n",
              "*   **Perceived Employment Gap (Post-2016):** The most significant weakness is the apparent gap in your professional data science experience since March 2016. While your education and projects are strong, the absence of any listed professional activity for the past 7+ years will raise questions from recruiters. This needs to be addressed clearly.\n",
              "*   **Resume Length and Relevance of Older Experience:** At two pages, the resume is longer than often preferred, especially given the age of some entries. The detailed inclusion of your Telecommunication Engineering M.S. (2005) and the extensive descriptions for sales roles from 2004-2013, while containing valuable achievements, take up significant space that could be better utilized for more recent, directly relevant data science content. The \"Tutor\" experience from 2002-2004 is also very old and not directly relevant.\n",
              "*   **\"Skills\" Section Not Fully Reflecting Project Expertise:** While you list Python and R, specific machine learning and deep learning frameworks explicitly used in your projects (e.g., TensorFlow, Scikit-Learn, OpenCV) are not listed in your \"Skills\" section. This is a missed opportunity to showcase expertise in highly sought-after tools upfront.\n",
              "*   **\"Professional Profile\" Could Be More Targeted:** The profile is good but slightly generic. Given your unique blend of experimental design, statistical rigor, and business acumen, it could be more sharply focused on the specific type of data science role you are seeking and what unique value you bring.\n",
              "*   **Lack of Recent Professional Data Science Roles:** Your two professional \"Data Scientist\" roles are relatively short-term (3-4 months each) and from 2014-2016. Employers often look for more sustained professional experience in data science.\n",
              "\n",
              "---\n",
              "\n",
              "### 3. Suggestions to Make It More Attractive to Employers\n",
              "\n",
              "To make your resume more impactful and address the identified weaknesses, consider the following suggestions:\n",
              "\n",
              "1.  **Address the Employment Gap Directly and Positively:**\n",
              "    *   **Explicitly State Recent Activities:** If you've been working on personal projects, self-study, freelancing, or other activities since 2016, create a new section (e.g., \"Independent Data Science Consultant,\" \"Continued Learning & Personal Projects\") with dates and bullet points describing your work, tools used, and results. This transforms a potential negative into a positive showing continuous engagement.\n",
              "    *   **Consider a Functional/Hybrid Resume:** If the gap is substantial, a hybrid resume that leads with a strong \"Skills\" and \"Projects\" section before chronologically listing professional experience might be effective.\n",
              "\n",
              "2.  **Condense for a Single-Page (or Highly Focused Two-Page) Resume:**\n",
              "    *   **Ruthlessly Prioritize:** Focus on your *most recent and most relevant* data science experience, skills, and projects.\n",
              "    *   **Streamline Older Experience:**\n",
              "        *   **Combine Sales Roles:** Create a section like \"Previous Business & Leadership Experience\" and summarize the YOKOGAWA and AYSCOM roles with 1-2 powerful, quantifiable bullet points *each*, emphasizing transferable skills (e.g., data-driven decision-making, team leadership, strategic analysis). Remove less critical details.\n",
              "        *   **Condense Oldest Degree:** For the 2005 Telecommunication Engineering M.S., list only the degree, university, and year. Remove GPA and focus area to save space.\n",
              "        *   **Remove Tutor Experience:** This is too old and not relevant enough for a data science role to warrant space on your resume.\n",
              "    *   By doing this, you should comfortably get to one page, or a very tight two pages, with the second page dedicated solely to robust projects.\n",
              "\n",
              "3.  **Enhance the \"Skills\" Section:**\n",
              "    *   **Add Specific ML/DL Frameworks:** Under \"Proficient\" or \"Intermediate,\" explicitly add `TensorFlow`, `Scikit-Learn`, and `OpenCV`. This immediately highlights your command of crucial ML/DL libraries.\n",
              "    *   **Consider \"Methodologies\" Category:** You could add a category like \"Methodologies\" and list \"Experimental Design,\" \"A/B Testing,\" \"Causal Inference,\" \"Time Series Analysis,\" \"ETL,\" \"Anomaly Detection,\" etc., as these are key strengths demonstrated in your work.\n",
              "\n",
              "4.  **Refine Your \"Professional Profile\" / Summary:**\n",
              "    *   **Targeted Value Proposition:** Make it more specific and outcome-oriented. Example: \"Highly analytical Data Scientist with dual Master's degrees and a proven track record in designing and implementing robust experimental frameworks and machine learning solutions. Seeking to leverage expertise in user behavior analytics, large-scale data processing, and statistical modeling to drive product innovation and measurable business growth.\"\n",
              "    *   **Consider a \"Highlights\" Section:** For a career transition or an individual with a strong project portfolio, a \"Highlights\" section (3-4 bullet points immediately after the profile) can quickly summarize your most impressive achievements or core competencies (e.g., \"Led design of cluster-randomized experiments for Google Spain,\" \"Developed scalable cloud-based video monitoring system,\" \"Increased operating income by 146%\").\n",
              "\n",
              "5.  **Tailor Your Resume for Each Application:**\n",
              "    *   **Keyword Optimization:** Review job descriptions carefully. Incorporate keywords from the job posting into your profile, project descriptions, and skill sections where genuinely applicable.\n",
              "    *   **Reorder Sections:** Depending on the specific role, consider moving your \"Projects\" section *above* your \"Experience\" section if the job heavily emphasizes hands-on technical skills and recent work, as your professional DS experience is older.\n",
              "\n",
              "By implementing these suggestions, Juan Jose, you can transform your resume into a highly targeted and impactful document that effectively showcases your strong data science capabilities and positions you as a top candidate for modern data science roles.\"\"\"\n",
              "          ),\n",
              "        ],\n",
              "        role='model'\n",
              "      ),\n",
              "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
              "      index=0\n",
              "    ),\n",
              "  ],\n",
              "  model_version='gemini-2.5-flash',\n",
              "  response_id='MJcJaa2vPM3Pz7IPj_iW2Qg',\n",
              "  sdk_http_response=HttpResponse(\n",
              "    headers=<dict len=10>\n",
              "  ),\n",
              "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
              "    candidates_token_count=1854,\n",
              "    prompt_token_count=1791,\n",
              "    prompt_tokens_details=[\n",
              "      ModalityTokenCount(\n",
              "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
              "        token_count=1791\n",
              "      ),\n",
              "    ],\n",
              "    thoughts_token_count=3724,\n",
              "    total_token_count=7369\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are an expert career advisor.\n",
        "Review the following resume and give feedback in 3 sections:\n",
        "1. Summary of strengths\n",
        "2. Weaknesses or areas to improve\n",
        "3. Suggestions to make it more attractive to employers.\n",
        "\n",
        "Focus on clarity, project impact, and keyword optimization for ATS systems.\n",
        "\n",
        "Resume content:\n",
        "{resume_text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gLjbbmURdwFn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=prompt\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIlKQiCWd0pV",
        "outputId": "00a8919c-b75d-45f7-f0c0-6f95e6c4f79a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a review of Juan Jose Carin's resume, structured into the three requested sections:\n",
            "\n",
            "## Resume Review: Juan Jose Carin - Data Scientist\n",
            "\n",
            "### 1. Summary of Strengths\n",
            "\n",
            "Juan Jose's resume presents a compelling profile for a Data Scientist, showcasing a robust foundation and a clear commitment to the field.\n",
            "\n",
            "*   **Exceptional Educational Background:** Juan Jose possesses an outstanding academic record, with two highly relevant Master's degrees – a Master of Information and Data Science from UC Berkeley and an M.S. in Statistical and Computational Information Processing from Universidad Politécnica de Madrid. The high GPAs (3.93 and 3.69) underscore his strong theoretical understanding and academic rigor. The list of relevant courses further highlights a comprehensive curriculum in machine learning, statistics, data storage, experimentation, and visualization.\n",
            "*   **Strong Technical Skills & Tool Proficiency:** The \"Skills\" section is excellent. It is well-categorized by proficiency and covers a broad array of essential data science tools, including programming languages (R, Python, SQL), big data technologies (Hadoop, Hive, Spark, Storm), visualization tools (Tableau, D3.js), and cloud platforms (AWS). This demonstrates a versatile and modern skillset highly sought after by employers.\n",
            "*   **Impressive Portfolio of Data Science Projects:** The \"Projects\" section is arguably the strongest part of the resume. It provides concrete examples of Juan Jose's hands-on experience in various data science domains, including machine learning, big data processing, experimental design, data visualization, and ETL. The projects clearly list the technologies used (e.g., TensorFlow, AWS, Hadoop, Spark, Scikit-Learn, R, SAS), showcasing practical application and a diverse problem-solving ability.\n",
            "*   **Demonstrated Impact and Analytical Thinking (Transferable):** Even in his older sales/management roles, Juan Jose highlights quantifiable achievements (e.g., \"Increased revenue by 6.3%, gross profit by 4.2%, and operating income by 146%\"). While not directly data science, this demonstrates a results-oriented mindset and an ability to use data (sales/market trends) to drive business outcomes, which are valuable transferable skills for a data scientist who needs to understand business context.\n",
            "*   **Clear Career Transition & Dedication:** The chronological progression of his education, particularly the recent Master's degrees, clearly illustrates a deliberate and successful career transition into data science, backed by significant academic and project-based effort.\n",
            "*   **Strong Online Presence:** Including links to LinkedIn and GitHub provides employers with easy access to further explore his professional network and code portfolio, which is crucial for data science roles.\n",
            "\n",
            "### 2. Weaknesses or Areas to Improve\n",
            "\n",
            "While the strengths are significant, there are several areas where the resume could be enhanced to be even more attractive to employers:\n",
            "\n",
            "*   **Lack of Recent, Sustained Professional Data Science Experience:** This is the most significant perceived weakness. The \"Data Science\" work experience at CONENTO consists of two short stints (3 months and 4 months) that are now several years old (2016 and 2014). While valuable, the lack of a sustained, full-time data science role since 2016 might raise questions about recent professional practice and team collaboration in a corporate environment.\n",
            "*   **Professional Profile Lacks Specificity and Punch:** The \"Professional Profile\" is a good start but too generic. It doesn't immediately convey *what kind* of Data Scientist Juan Jose is (e.g., ML Engineer, Experimentation Scientist, Analytics Engineer), his core expertise, or his most compelling achievements. It misses an opportunity to grab the reader's attention with specific, high-impact statements from his projects or education.\n",
            "*   **Over-Emphasis on Older, Non-Data Science Experience:** A substantial portion of the resume (Feb. 2009 – Aug. 2013 and earlier) is dedicated to Sales and Management roles. While they demonstrate transferable skills, these roles are chronologically prominent and not directly data science-related, potentially overshadowing his more relevant skills and recent data science efforts. For a data science role, this could lead to an employer quickly overlooking his technical prowess.\n",
            "*   **Project Descriptions Could Emphasize Impact More Explicitly:** While the projects are well-listed with technologies, many descriptions could be strengthened by articulating the *business problem solved*, the *insights gained*, or the *quantifiable impact* of the work. For example, \"A scalable cloud-based video monitoring system...\" is good, but what problem did it solve? What was its potential benefit?\n",
            "*   **Minor Keyword Optimization Gaps in Experience:** While the skills section is rich in keywords, integrating more specific data science methodologies, statistical techniques, and types of models *within* the experience and project bullet points would further enhance ATS matching, especially for roles requiring advanced ML or experimental design. For example, mentioning \"causal inference,\" \"A/B testing frameworks,\" \"feature engineering,\" or \"model deployment lifecycle.\"\n",
            "*   **Formatting Inconsistencies & Redundancy:** The repetition of contact information on the second page is unnecessary and consumes valuable space. Date formatting is also inconsistent (e.g., \"Jan. 2016 – Mar. 2016\" vs. just \"2016\").\n",
            "\n",
            "### 3. Suggestions to Make it More Attractive to Employers\n",
            "\n",
            "To optimize this resume for clarity, project impact, and ATS keyword optimization, I recommend the following:\n",
            "\n",
            "1.  **Revamp the Professional Profile (Summary):**\n",
            "    *   **Be Specific and Impactful:** Transform this into a concise (3-4 sentences) value proposition. Highlight your most compelling skills and experiences upfront.\n",
            "    *   **Focus on Key Strengths:** Start with your unique blend of advanced education (mention UC Berkeley & UPM), key technical expertise (e.g., \"Machine Learning, Experimental Design, Big Data Engineering\"), and ability to drive business insights.\n",
            "    *   **Embed Keywords & Quantify:** \"Highly accomplished Data Scientist with two Master's degrees from UC Berkeley (3.93 GPA) and UPM, specializing in **machine learning, experimental design, predictive modeling, and cloud-based data solutions**. Proven ability to leverage Python, R, Spark, and AWS to build scalable systems (e.g., real-time video analytics) and design rigorous experiments that deliver actionable business insights and growth.\"\n",
            "\n",
            "2.  **Re-structure Experience to Emphasize Data Science:**\n",
            "    *   **Create a \"Data Science Experience\" Section:** Group *all* professional data science work, starting with your most recent (even if short) roles.\n",
            "    *   **Elevate and Enhance CONENTO Descriptions:** For the CONENTO roles, add more detail about the impact.\n",
            "        *   *Example ETL:* \"Designed and implemented a robust **ETL pipeline** (R, MySQL) for a predictive traffic model, processing multi-source data (sensors, accidents, weather) and **automating anomaly detection** to provide critical insights for the Spanish government.\"\n",
            "        *   *Example Experimentation:* \"Designed and executed a **matched-pair, cluster-randomized experiment** for Google Spain (R, wavelets) to measure the causal impact of YouTube ads on car sales across 50+ cities, delivering data-driven recommendations for marketing strategy.\"\n",
            "    *   **Consider a \"Key Data Science Projects\" or \"Applied Data Science\" Section:** This section would follow \"Data Science Experience\" (or even precede it if you want to emphasize projects over limited tenure). This is where your strong \"Projects\" section can shine even brighter.\n",
            "\n",
            "3.  **Condense and Reframe Older Experience:**\n",
            "    *   **Create a \"Previous Experience\" or \"Leadership & Sales\" Section:** Place your older Sales and Management roles *after* your core Data Science sections (Experience, Projects, Education).\n",
            "    *   **Focus on Transferable Skills and Quantifiable Business Impact:** For these roles, significantly shorten the descriptions, focusing solely on bullet points that highlight leadership, strategic decision-making, stakeholder management, business acumen, and quantifiable results. Frame it in terms of using *data* or *analysis* for business growth.\n",
            "        *   *Example:* \"Led a team of 7 people, leveraging market trend analysis to increase revenue by 6.3%, gross profit by 4.2%, and operating income by 146% for the Test & Measurement department.\"\n",
            "    *   **Consider Date Truncation:** For very old roles (e.g., the Tutor role from 2002-2004), you might list just \"Academia Universitaria – Tutor (2002-2004)\" without bullet points, or move it to an \"Other Experience\" section if space is critical.\n",
            "\n",
            "4.  **Enhance Project Descriptions with Explicit Impact & Keywords:**\n",
            "    *   **Quantify Outcomes:** For every project, ask \"What was the result? What problem did it solve? What was the benefit or insight?\"\n",
            "        *   *SmartCam:* \"Developed a scalable cloud-based video monitoring system (Python, OpenCV, TensorFlow, AWS) featuring motion detection, face counting, and image recognition, **designed to enhance security monitoring efficiency and provide real-time occupancy analytics.**\"\n",
            "        *   *Forest Cover:* \"Participated in a Kaggle competition, leveraging **random forests, SVMs, kNNs, and Gradient Descent** to predict forest cover type with X% accuracy from cartographic variables, showcasing advanced **machine learning model comparison and selection** skills.\"\n",
            "        *   *Job Search Process:* \"Developed a **data pipeline** (Hadoop HDFS, Hive, Spark, Python, AWS, Tableau) combining Indeed API and U.S. Census Bureau data to identify optimal locations for data scientists, **providing data-driven insights on job market demand vs. cost of living.**\"\n",
            "        *   *Churn Prediction:* \"Built **predictive models (decision trees, logistic regression, neural networks)** in SAS from 45,000+ customer data points to forecast mobile network carrier churn, **enabling targeted retention strategies.**\"\n",
            "    *   **Integrate Methodologies:** Explicitly weave in advanced concepts like \"A/B testing,\" \"causal inference,\" \"feature engineering,\" \"model evaluation metrics,\" \"ETL design,\" \"data warehousing,\" etc., where applicable.\n",
            "\n",
            "5.  **Refine Skills Section for ATS and Clarity:**\n",
            "    *   **Add \"Methodologies/Techniques\" Category:** Include a section specifically for data science methodologies like \"Experimental Design,\" \"A/B Testing,\" \"Causal Inference,\" \"Time Series Analysis,\" \"Predictive Modeling,\" \"ETL Design,\" \"Feature Engineering,\" \"Statistical Modeling,\" \"Hypothesis Testing.\"\n",
            "    *   **Group by Function (Optional):** Consider grouping skills by function (e.g., \"Programming Languages,\" \"Machine Learning Libraries,\" \"Big Data Frameworks,\" \"Cloud Platforms,\" \"Databases,\" \"Data Visualization\") instead of just proficiency levels, as ATS often searches for these categories.\n",
            "\n",
            "6.  **Formatting and Consistency:**\n",
            "    *   **Remove Redundant Contact Info:** On page 2, delete the repeated contact information to free up space.\n",
            "    *   **Standardize Date Formats:** Choose one consistent format (e.g., \"Jan 2016 – Mar 2016\" or \"01/2016 – 03/2016\") and apply it throughout the resume.\n",
            "    *   **Concise Bullet Points:** Ensure each bullet point is impactful and starts with a strong action verb.\n",
            "\n",
            "By implementing these suggestions, Juan Jose's resume will present a clearer, more powerful narrative of his data science capabilities, address the perceived gaps in professional experience, and significantly increase its attractiveness to potential employers and ATS systems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "Q80Qx1-ee_V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are an expert career advisor.\n",
        "Review the following resume and give feedback in 3 sections:\n",
        "1. Summary of strengths\n",
        "2. Weaknesses or areas to improve\n",
        "3. Suggestions to make it more attractive to employers.\n",
        "\n",
        "Focus on clarity, project impact, and keyword optimization for ATS systems.\n",
        "\n",
        "Resume content:\n",
        "{resume_text}\n",
        "\n",
        "give me output format as thai langauge\n",
        "\"\"\"\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=prompt\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKt3Q25Dd0mf",
        "outputId": "ec2ec157-8f16-46fa-89d4-7449ded1a9b2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ในฐานะที่ปรึกษาด้านอาชีพผู้เชี่ยวชาญ ดิฉันได้ทำการตรวจสอบเรซูเม่ของ Juan Jose Carin แล้ว และขอให้ข้อเสนอแนะเพื่อช่วยให้เรซูเม่ของท่านน่าสนใจยิ่งขึ้นสำหรับนายจ้าง โดยเน้นที่ความชัดเจน ผลกระทบของโครงการ และการเพิ่มประสิทธิภาพคำหลักสำหรับระบบ ATS\n",
            "\n",
            "---\n",
            "\n",
            "**1. จุดแข็งโดยสรุป (Summary of Strengths)**\n",
            "\n",
            "Juan Jose Carin มีเรซูเม่ที่แข็งแกร่งและน่าประทับใจ โดยเฉพาะอย่างยิ่งในสายงาน Data Scientist จุดแข็งหลักๆ มีดังนี้:\n",
            "\n",
            "*   **พื้นฐานทางการศึกษาที่ยอดเยี่ยมและหลากหลาย:** ด้วยปริญญาโทสองใบในสาขาที่เกี่ยวข้องกับ Data Science โดยตรงจากมหาวิทยาลัยชั้นนำ (UC Berkeley และ Universidad Politécnica de Madrid) พร้อมเกรดเฉลี่ยที่สูงมาก แสดงให้เห็นถึงความรู้เชิงลึกและทฤษฎีที่แข็งแกร่ง\n",
            "*   **ทักษะทางเทคนิคที่ครอบคลุมและเชี่ยวชาญ:** มีความสามารถรอบด้านในเครื่องมือและภาษาสำคัญสำหรับ Data Science เช่น R, Python, SQL และประสบการณ์กับ Big Data technologies (Hadoop, Hive, MrJob) การแสดงระดับความชำนาญ (Proficient, Intermediate, Basic) ช่วยให้นายจ้างประเมินทักษะได้ง่าย\n",
            "*   **ประสบการณ์ Data Science ที่เกี่ยวข้องโดยตรงและมีผลลัพธ์:** ประสบการณ์ที่ CONENTO แสดงให้เห็นถึงความสามารถในการออกแบบและใช้งาน ETL pipeline, การทำนายผล, การออกแบบการทดลองทางสถิติ (matched-pair, cluster-randomized design) และการวิเคราะห์ข้อมูลเชิงลึก\n",
            "*   **ผลงานจากประสบการณ์ทำงานในอดีตที่จับต้องได้และมีผลกระทบทางธุรกิจ:** แม้ว่าประสบการณ์ด้าน Sales และ Management จะไม่ใช่ Data Science โดยตรง แต่ก็ได้แสดงให้เห็นถึงทักษะความเป็นผู้นำ การวิเคราะห์แนวโน้มตลาด และการสร้างผลลัพธ์ทางธุรกิจที่ชัดเจน (เช่น เพิ่มรายได้ 6.3%, กำไรจากการดำเนินงาน 146%) ซึ่งเป็นคุณสมบัติที่สำคัญสำหรับ Data Scientist ที่ต้องขับเคลื่อนคุณค่าทางธุรกิจ\n",
            "*   **พอร์ตโฟลิโอโครงการที่น่าประทับใจและหลากหลาย:** ส่วน Projects เป็นจุดแข็งที่โดดเด่นอย่างยิ่ง แสดงให้เห็นถึงการประยุกต์ใช้ Machine Learning, Deep Learning, Big Data, Cloud computing (AWS), การออกแบบการทดลอง และ Data Visualization ในหลากหลายบริบท ทำให้เห็นถึงความสามารถในการแก้ปัญหาที่ซับซ้อนด้วยเครื่องมือและเทคนิคที่แตกต่างกัน\n",
            "*   **การใช้คำหลัก (Keywords) ได้อย่างมีประสิทธิภาพ:** เรซูเม่ใช้คำหลักที่เกี่ยวข้องกับ Data Science เป็นจำนวนมาก ซึ่งเป็นประโยชน์อย่างยิ่งต่อระบบ ATS (Applicant Tracking Systems)\n",
            "*   **ข้อมูลติดต่อและลิงก์เสริมที่ครบถ้วน:** มีลิงก์ไปยัง LinkedIn และ GitHub ซึ่งสำคัญมากสำหรับ Data Scientist ในการแสดงผลงานเพิ่มเติม\n",
            "\n",
            "**2. จุดอ่อนหรือด้านที่ควรปรับปรุง (Weaknesses or Areas to Improve)**\n",
            "\n",
            "แม้ว่าเรซูเม่จะแข็งแกร่งมาก แต่ก็มีบางจุดที่สามารถปรับปรุงเพื่อให้ดียิ่งขึ้นไปอีก:\n",
            "\n",
            "*   **Professional Profile ที่ค่อนข้างกว้าง:** ข้อความสรุปประวัติส่วนตัวยังขาดความเฉพาะเจาะจงและผลลัพธ์เชิงปริมาณที่โดดเด่น ซึ่งอาจทำให้นายจ้างไม่เห็น \"คุณค่าเฉพาะ\" ของท่านได้ทันที\n",
            "*   **ความยาวของเรซูเม่และเนื้อหาที่อาจไม่เกี่ยวข้องโดยตรง:** เรซูเม่มีความยาว 2 หน้า ซึ่งสามารถยอมรับได้สำหรับผู้มีประสบการณ์ แต่มีบางส่วนที่อาจตัดออกหรือย่อให้กระชับลงได้ เช่น \"Focus Area\" ในปริญญาตรีด้าน Telecommunication Engineering หรือประสบการณ์การเป็นติวเตอร์เมื่อหลายปีก่อน ซึ่งอาจไม่เกี่ยวข้องโดยตรงกับตำแหน่ง Data Science ที่กำลังมองหา\n",
            "*   **ระดับความชำนาญของทักษะ Big Data บางอย่าง:** ทักษะอย่าง Spark และ Storm ที่ระบุว่าเป็น \"Intermediate\" อาจเป็นจุดที่ต้องพิจารณา หากเป้าหมายคือตำแหน่ง Senior Data Scientist ที่ต้องทำงานกับ Big Data ขนาดใหญ่เป็นหลัก ควรพยายามยกระดับเป็น \"Proficient\"\n",
            "*   **การเชื่อมโยงประสบการณ์ Sales/Management กับ Data Science:** แม้ว่าผลลัพธ์เชิงปริมาณในบทบาท Sales/Management จะดีเยี่ยม แต่การเชื่อมโยงโดยตรงกับทักษะการวิเคราะห์ข้อมูลที่นำไปสู่ผลลัพธ์เหล่านั้นยังไม่ชัดเจนในทุกประเด็น\n",
            "*   **การจัดเรียงหัวข้อที่ไม่เป็นลำดับเวลา:** ประสบการณ์ \"Tutor\" ที่เป็นช่วงปี 2002-2004 แต่มาปรากฏอยู่ท้ายสุดหลังจากส่วน Projects ซึ่งเป็นงานล่าสุด ทำให้ลำดับเวลาดูไม่ต่อเนื่อง\n",
            "\n",
            "**3. ข้อเสนอแนะเพื่อเพิ่มความน่าดึงดูดใจให้กับนายจ้าง (Suggestions to Make It More Attractive to Employers)**\n",
            "\n",
            "เพื่อเพิ่มความน่าดึงดูดใจให้เรซูเม่ของ Juan Jose Carin ดิฉันขอแนะนำดังนี้:\n",
            "\n",
            "*   **ปรับปรุง Professional Profile ให้โดดเด่นและกระชับ:**\n",
            "    *   เริ่มต้นด้วยประโยคที่เน้นคุณค่าและผลลัพธ์ที่เป็นเอกลักษณ์ของท่านทันที\n",
            "    *   รวมเอาทักษะหลักและผลลัพธ์เชิงปริมาณที่สำคัญที่สุดเข้าไว้ด้วยกัน เช่น \"Highly analytical Data Scientist with [จำนวนปีประสบการณ์ที่เกี่ยวข้อง] years of experience leveraging advanced statistical modeling, experimental design, and big data technologies (R, Python, Spark, AWS) to drive significant business growth, including achieving a 146% increase in operating income. Proven ability to translate user behavior insights into actionable strategies and build scalable data solutions.\"\n",
            "    *   ปรับแต่งส่วนนี้ให้เข้ากับคำอธิบายงาน (Job Description) ของตำแหน่งที่ท่านสมัคร\n",
            "*   **เน้นย้ำผลกระทบเชิงปริมาณให้มากยิ่งขึ้น:**\n",
            "    *   ทบทวนแต่ละ bullet point ในส่วนประสบการณ์ทำงานและโครงการ หากมีตัวเลข ผลลัพธ์ หรือการประหยัดเวลา/เงินที่สามารถเพิ่มเข้าไปได้ ให้ใส่เข้าไป\n",
            "    *   ตัวอย่างเช่น สำหรับประสบการณ์ Data Scientist ที่ CONENTO สามารถระบุขนาดข้อมูลที่ประมวลผล, ความแม่นยำของโมเดล (หากทำได้) หรือผลลัพธ์ที่เกิดจากการปรับปรุง ETL pipeline\n",
            "*   **ปรับปรุงทักษะ Big Data \"Intermediate\" ให้เป็น \"Proficient\":**\n",
            "    *   หากเป้าหมายคือตำแหน่งที่เน้น Big Data เป็นหลัก ให้พิจารณาหาโอกาสฝึกฝนหรือทำโปรเจกต์ที่ใช้ Spark และ Storm เพื่อยกระดับความชำนาญและอัปเดตในเรซูเม่\n",
            "*   **เชื่อมโยงประสบการณ์ Sales/Management เข้ากับ Data Science อย่างชัดเจน:**\n",
            "    *   ในส่วนประสบการณ์ Sales/Management ให้เพิ่ม bullet point หรือปรับปรุงข้อความที่มีอยู่เพื่อเน้นย้ำถึงการใช้ข้อมูล การวิเคราะห์ หรือการตัดสินใจโดยอิงข้อมูลในบทบาทเหล่านั้น\n",
            "    *   ตัวอย่าง: \"Applied **data-driven analysis** of sales and market trends to decide the strategic direction of the department.\" หรือ \"Led a team of 7 people, leveraging **performance data and analytics** to optimize sales strategies and improve customer service.\"\n",
            "*   **พิจารณาการจัดเรียงและตัดทอนเนื้อหาที่ไม่จำเป็น:**\n",
            "    *   ย้ายประสบการณ์ \"Tutor\" ไปไว้ในส่วน \"Additional Experience\" ที่แยกต่างหาก หรืออาจพิจารณาลบออกหากต้องการให้เรซูเม่กระชับเหลือ 1 หน้า และเน้นไปที่ประสบการณ์ที่ทันสมัยกว่า\n",
            "    *   ตัด \"Focus Area: Radio communication systems (radar and mobile)\" ออกจากปริญญา Telecommunication Engineering เพราะไม่เกี่ยวข้องโดยตรงกับ Data Science ในปัจจุบัน เพื่อประหยัดพื้นที่และเน้นความ relevancy\n",
            "    *   อาจพิจารณาการจัดกลุ่ม \"Skills\" ให้กระชับขึ้น เช่นรวม Big Data, Visualization, และ Other เข้าด้วยกันหากพื้นที่จำกัด\n",
            "*   **สร้างส่วน \"Key Achievements\" (ผลงานสำคัญ) สั้นๆ:**\n",
            "    *   อาจเพิ่มหัวข้อสั้นๆ ใต้ Professional Profile ที่แสดง 3-5 ความสำเร็จที่สำคัญที่สุดและมีผลกระทบเชิงปริมาณจากทั้งบทบาท Data Science และ Sales/Management เพื่อดึงดูดความสนใจของผู้อ่านในทันที\n",
            "*   **เพิ่มประสิทธิภาพคำหลักอย่างต่อเนื่อง:**\n",
            "    *   ทบทวนคำอธิบายงาน (Job Descriptions) ที่ท่านสนใจ และตรวจสอบให้แน่ใจว่าคำหลักสำคัญเหล่านั้นถูกรวมอยู่ใน Professional Profile, Skills, Experience และ Projects ของท่าน\n",
            "*   **ใช้ Action Verbs ที่แข็งแกร่งและสอดคล้องกัน:**\n",
            "    *   ตรวจสอบให้แน่ใจว่าแต่ละ bullet point เริ่มต้นด้วย Action Verb ที่ทรงพลังและสื่อถึงการกระทำและผลลัพธ์ที่ชัดเจน\n",
            "\n",
            "การปรับปรุงเหล่านี้จะช่วยให้เรซูเม่ของ Juan Jose Carin มีความชัดเจน โดดเด่น และสื่อสารคุณค่าของท่านได้ดียิ่งขึ้นต่อนายจ้าง โดยเฉพาะอย่างยิ่งในการแสดงให้เห็นว่าท่านเป็น Data Scientist ที่ไม่เพียงแต่มีความเชี่ยวชาญด้านเทคนิคเท่านั้น แต่ยังสามารถสร้างผลกระทบทางธุรกิจที่แท้จริงได้อีกด้วย\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are an expert data extractor for resumes.\n",
        "\n",
        "Analyze the following resume and output ONLY valid JSON (no explanations, no markdown).\n",
        "\n",
        "Extract these fields:\n",
        "- full_name (string)\n",
        "- contact_info (string or dict if multiple)\n",
        "- education (list of objects with degree, field, institution, year)\n",
        "- work_experience (list of objects with company, role, start_date, end_date, key_achievements)\n",
        "- skills (list of strings)\n",
        "- certifications (list of strings)\n",
        "- languages (list of strings)\n",
        "- projects (list of objects with name, description, technologies)\n",
        "- summary (string: brief professional summary in Thai language)\n",
        "\n",
        " If any field is missing, return an empty string or empty list.\n",
        "\n",
        "Resume content:\n",
        "{resume_text}\n",
        "\"\"\"\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=prompt\n",
        ")\n",
        "\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrhHRpZGd0jm",
        "outputId": "5a4d4452-f444-4906-e98e-945899cd5e51"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"full_name\": \"Juan Jose Carin\",\n",
            "  \"contact_info\": \"650-336-4590 | juanjose.carin@gmail.com | linkedin.com/in/juanjosecarin | juanjocarin.github.io\",\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Master of Information and Data Science\",\n",
            "      \"field\": \"Information and Data Science\",\n",
            "      \"institution\": \"University of California, Berkeley\",\n",
            "      \"year\": \"2016\"\n",
            "    },\n",
            "    {\n",
            "      \"degree\": \"M.S.\",\n",
            "      \"field\": \"Statistical and Computational Information Processing\",\n",
            "      \"institution\": \"Universidad Politécnica de Madrid\",\n",
            "      \"year\": \"2014\"\n",
            "    },\n",
            "    {\n",
            "      \"degree\": \"M.S.\",\n",
            "      \"field\": \"Telecommunication Engineering\",\n",
            "      \"institution\": \"Universidad Politécnica de Madrid\",\n",
            "      \"year\": \"2005\"\n",
            "    }\n",
            "  ],\n",
            "  \"work_experience\": [\n",
            "    {\n",
            "      \"company\": \"CONENTO\",\n",
            "      \"role\": \"Data Scientist\",\n",
            "      \"start_date\": \"Jan. 2016\",\n",
            "      \"end_date\": \"Mar. 2016\",\n",
            "      \"key_achievements\": [\n",
            "        \"Designed and implemented the ETL pipeline for a predictive model of traffic on the main roads in eastern Spain (a project for the Spanish government).\",\n",
            "        \"Automated scripts in R to extract, transform, clean (incl. anomaly detection), and load into MySQL data from multiple data sources: road traffic sensors, accidents, road works, weather.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"CONENTO\",\n",
            "      \"role\": \"Data Scientist\",\n",
            "      \"start_date\": \"Jun. 2014\",\n",
            "      \"end_date\": \"Sep. 2014\",\n",
            "      \"key_achievements\": [\n",
            "        \"Designed an experiment for Google Spain (conducted in October 2014) to measure the impact of YouTube ads on the sales of a car manufacturer's dealer network.\",\n",
            "        \"A matched-pair, cluster-randomized design, which involved selecting the test and control groups from a sample of 50+ cities in Spain (where geo-targeted ads were possible) based on their sales-wise similarity over time, using wavelets (and R).\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"YOKOGAWA\",\n",
            "      \"role\": \"Head of Sales, Spain & Portugal – Test &Measurement dept.\",\n",
            "      \"start_date\": \"Feb. 2009\",\n",
            "      \"end_date\": \"Aug. 2013\",\n",
            "      \"key_achievements\": [\n",
            "        \"Applied analysis of sales and market trends to decide the direction of the department.\",\n",
            "        \"Led a team of 7 people.\",\n",
            "        \"Increased revenue by 6.3%, gross profit by 4.2%, and operating income by 146%, and achieved a 30% ratio of new customers (3x growth), by entering new markets and improving customer service and training.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"YOKOGAWA\",\n",
            "      \"role\": \"Sales Engineer – Test & Measurement dept.\",\n",
            "      \"start_date\": \"Apr. 2008\",\n",
            "      \"end_date\": \"Jan. 2009\",\n",
            "      \"key_achievements\": [\n",
            "        \"Promoted to head of sales after 5 months leading the sales team.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"AYSCOM\",\n",
            "      \"role\": \"Sales & Application Engineer\",\n",
            "      \"start_date\": \"Sep. 2004\",\n",
            "      \"end_date\": \"Mar. 2008\",\n",
            "      \"key_achievements\": [\n",
            "        \"Exceeded sales target every year from 2005 to 2007 (achieved 60% of the target in the first 3 months of 2008).\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"ACADEMIA UNIVERSITARIA\",\n",
            "      \"role\": \"Tutor of Differential & Integral Calculus, Physics, and Digital Electronic Circuits\",\n",
            "      \"start_date\": \"Jul. 2002\",\n",
            "      \"end_date\": \"Jun. 2004\",\n",
            "      \"key_achievements\": [\n",
            "        \"Highest-rated professor in student surveys, in 4 of the 6 terms.\",\n",
            "        \"Increased ratio of students passing the course by 25%.\"\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"skills\": [\n",
            "    \"R\",\n",
            "    \"Python\",\n",
            "    \"SQL\",\n",
            "    \"Hadoop\",\n",
            "    \"Hive\",\n",
            "    \"MrJob\",\n",
            "    \"Tableau\",\n",
            "    \"Git\",\n",
            "    \"AWS\",\n",
            "    \"SPSS\",\n",
            "    \"SAS\",\n",
            "    \"Matlab\",\n",
            "    \"Spark\",\n",
            "    \"Storm\",\n",
            "    \"Bash\",\n",
            "    \"EViews\",\n",
            "    \"Demetra+\",\n",
            "    \"D3.js\",\n",
            "    \"Gephi\",\n",
            "    \"Neo4j\",\n",
            "    \"QGIS\"\n",
            "  ],\n",
            "  \"certifications\": [],\n",
            "  \"languages\": [],\n",
            "  \"projects\": [\n",
            "    {\n",
            "      \"name\": \"SmartCam\",\n",
            "      \"description\": \"A scalable cloud-based video monitoring system that features motion detection, face counting, and image recognition.\",\n",
            "      \"technologies\": \"Python, OpenCV, TensorFlow, AWS (EC2, S3, DynamoDB)\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Implementation of the Shortest Path and PageRank algorithms with the Wikipedia graph dataset\",\n",
            "      \"description\": \"Using a graph dataset of almost half a million nodes.\",\n",
            "      \"technologies\": \"Hadoop MrJob, Python, AWS EC2, AWS S3\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Forest cover type prediction\",\n",
            "      \"description\": \"A Kaggle competition: predictions of the predominant kind of tree cover, from strictly cartographic variables such as elevation and soil type, using random forests, SVMs, kNNs, Naive Bayes, Gradient Descent, GMMs, …\",\n",
            "      \"technologies\": \"Python, Scikit-Learn, Matplotlib\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Redefining the job search process\",\n",
            "      \"description\": \"A pipeline that combines data from Indeed API and the U.S. Census Bureau to select the best locations for data scientists based on the number of job postings, housing cost, etc.\",\n",
            "      \"technologies\": \"Hadoop HDFS, Hive, Spark, Python, AWS EC2, Tableau\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"A fresh perspective on Citi Bike\",\n",
            "      \"description\": \"An interactive website to visualize NYC Citi Bike bicycle sharing service.\",\n",
            "      \"technologies\": \"Tableau, SQLite\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Investigating the effect of competition on the ability to solve arithmetic problems\",\n",
            "      \"description\": \"A randomized controlled trial in which 300+ participants were assigned to a control group or one of two test groups to evaluate the effect of competition (being compared to no one or someone better or worse).\",\n",
            "      \"technologies\": \"R\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Prediction of customer churn for a mobile network carrier\",\n",
            "      \"description\": \"Predictions from a sample of 45,000+ customers, using tree decisions, logistic regression, and neural networks.\",\n",
            "      \"technologies\": \"SAS\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Different models of Harmonized Index of Consumer Prices (HICP) in Spain\",\n",
            "      \"description\": \"Forecasts based on exponential smoothing, ARIMA, and transfer function (using petrol price as independent variable) models.\",\n",
            "      \"technologies\": \"SPSS, Demetra+\"\n",
            "    }\n",
            "  ],\n",
            "  \"summary\": \"มีความกระตือรือร้นในการวิเคราะห์ข้อมูลและการทดลอง โดยเน้นหลักไปที่พฤติกรรม ประสบการณ์ และการมีส่วนร่วมของผู้ใช้งาน ด้วยพื้นฐานที่แข็งแกร่งด้านวิทยาศาสตร์ข้อมูลและสถิติ และมีประสบการณ์มากมายในการใช้ข้อมูลเชิงลึกเพื่อขับเคลื่อนการเติบโตทางธุรกิจ\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rskills = [\n",
        "    \"R\",\n",
        "    \"Python\",\n",
        "    \"SQL\",\n",
        "    \"Hadoop\",\n",
        "    \"Hive\",\n",
        "    \"MrJob\",\n",
        "    \"Tableau\",\n",
        "    \"Git\",\n",
        "    \"AWS\",\n",
        "    \"SPSS\",\n",
        "    \"SAS\",\n",
        "    \"Matlab\",\n",
        "    \"Spark\",\n",
        "    \"Storm\",\n",
        "    \"Bash\",\n",
        "    \"EViews\",\n",
        "    \"Demetra+\",\n",
        "    \"D3.js\",\n",
        "    \"Gephi\",\n",
        "    \"Neo4j\",\n",
        "    \"QGIS\"\n",
        "  ]"
      ],
      "metadata": {
        "id": "Iin0GQ22mbu5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Iskills = [\n",
        "  \"Python\",\n",
        "  \"R\",\n",
        "  \"SQL\",\n",
        "  \"Git\",\n",
        "  \"Linux\",\n",
        "  \"Bash\",\n",
        "  \"Docker\",\n",
        "  \"Kubernetes\",\n",
        "  \"Airflow\",\n",
        "  \"Spark\",\n",
        "  \"Hadoop\",\n",
        "  \"Hive\",\n",
        "  \"Snowflake\",\n",
        "  \"BigQuery\",\n",
        "  \"Redshift\",\n",
        "  \"AWS\",\n",
        "  \"GCP\",\n",
        "  \"Azure\",\n",
        "  \"S3\",\n",
        "  \"SageMaker\",\n",
        "  \"Vertex AI\",\n",
        "  \"Terraform\",\n",
        "  \"NumPy\",\n",
        "  \"pandas\",\n",
        "  \"Matplotlib\",\n",
        "  \"Seaborn\",\n",
        "  \"Plotly\",\n",
        "  \"Power BI\",\n",
        "  \"Tableau\",\n",
        "  \"scikit-learn\",\n",
        "  \"XGBoost\",\n",
        "  \"LightGBM\",\n",
        "  \"CatBoost\",\n",
        "  \"TensorFlow\",\n",
        "  \"PyTorch\",\n",
        "  \"Keras\",\n",
        "  \"MLflow\",\n",
        "  \"Optuna\",\n",
        "  \"LangChain\",\n",
        "  \"LangGraph\",\n",
        "  \"OpenAI API\",\n",
        "  \"Hugging Face\",\n",
        "  \"Transformers\",\n",
        "  \"FastAPI\",\n",
        "  \"Flask\",\n",
        "  \"Streamlit\",\n",
        "  \"PostgreSQL\",\n",
        "  \"MySQL\",\n",
        "  \"MongoDB\",\n",
        "  \"Neo4j\",\n",
        "  \"Qdrant\",\n",
        "  \"Pinecone\",\n",
        "  \"Vertex AI Matching Engine\",\n",
        "  \"Data Cleaning\",\n",
        "  \"Feature Engineering\",\n",
        "  \"Model Evaluation\",\n",
        "  \"A/B Testing\",\n",
        "  \"Time Series Analysis\",\n",
        "  \"NLP\",\n",
        "  \"Computer Vision\",\n",
        "  \"Reinforcement Learning\",\n",
        "  \"MLOps\",\n",
        "  \"LLMOps\",\n",
        "  \"Vector Databases\",\n",
        "  \"ETL/ELT\",\n",
        "  \"Data Warehouse Design\",\n",
        "  \"CI/CD\",\n",
        "  \"Statistics\",\n",
        "  \"Probability\",\n",
        "  \"Linear Algebra\",\n",
        "  \"Calculus\",\n",
        "  \"Data Storytelling\",\n",
        "  \"Business Analysis\",\n",
        "  \"Agile / Scrum\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "zHk8qWSrd0gr"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rsk = set(Rskills)\n",
        "Isk = set(Iskill)"
      ],
      "metadata": {
        "id": "WMjuPN2Yd0du"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jaccard_score = len(Rsk&Isk)/len(Rsk|Isk)\n",
        "jaccard_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRKjHfTGmz6P",
        "outputId": "e1e076f3-197d-4611-9112-6e91b4d0ae22"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13095238095238096"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Isk-Rsk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmNPOBq9nGzu",
        "outputId": "7e95eb4a-32d3-426c-a584-455921933895"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A/B Testing',\n",
              " 'Agile / Scrum',\n",
              " 'Airflow',\n",
              " 'Azure',\n",
              " 'BigQuery',\n",
              " 'Business Analysis',\n",
              " 'CI/CD',\n",
              " 'Calculus',\n",
              " 'CatBoost',\n",
              " 'Computer Vision',\n",
              " 'Data Cleaning',\n",
              " 'Data Storytelling',\n",
              " 'Data Warehouse Design',\n",
              " 'Docker',\n",
              " 'ETL/ELT',\n",
              " 'FastAPI',\n",
              " 'Feature Engineering',\n",
              " 'Flask',\n",
              " 'GCP',\n",
              " 'Hugging Face',\n",
              " 'Keras',\n",
              " 'Kubernetes',\n",
              " 'LLMOps',\n",
              " 'LangChain',\n",
              " 'LangGraph',\n",
              " 'LightGBM',\n",
              " 'Linear Algebra',\n",
              " 'Linux',\n",
              " 'MLOps',\n",
              " 'MLflow',\n",
              " 'Matplotlib',\n",
              " 'Model Evaluation',\n",
              " 'MongoDB',\n",
              " 'MySQL',\n",
              " 'NLP',\n",
              " 'NumPy',\n",
              " 'OpenAI API',\n",
              " 'Optuna',\n",
              " 'Pinecone',\n",
              " 'Plotly',\n",
              " 'PostgreSQL',\n",
              " 'Power BI',\n",
              " 'Probability',\n",
              " 'PyTorch',\n",
              " 'Qdrant',\n",
              " 'Redshift',\n",
              " 'Reinforcement Learning',\n",
              " 'S3',\n",
              " 'SageMaker',\n",
              " 'Seaborn',\n",
              " 'Snowflake',\n",
              " 'Statistics',\n",
              " 'Streamlit',\n",
              " 'TensorFlow',\n",
              " 'Terraform',\n",
              " 'Time Series Analysis',\n",
              " 'Transformers',\n",
              " 'Vector Databases',\n",
              " 'Vertex AI',\n",
              " 'Vertex AI Matching Engine',\n",
              " 'XGBoost',\n",
              " 'pandas',\n",
              " 'scikit-learn'}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rsk-Isk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQr9nhM5nSA0",
        "outputId": "acab0181-2a27-4510-ca00-c8f8846a5a25"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'D3.js',\n",
              " 'Demetra+',\n",
              " 'EViews',\n",
              " 'Gephi',\n",
              " 'Matlab',\n",
              " 'MrJob',\n",
              " 'QGIS',\n",
              " 'SAS',\n",
              " 'SPSS',\n",
              " 'Storm'}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = {\"HTML\",\"CSS\",\"Js\"}\n",
        "y = {\"HTML\",\"CSS\"}"
      ],
      "metadata": {
        "id": "L3GMtVlIpwjg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x&y)/len(x|y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asnr2Mxbp51L",
        "outputId": "f6d8d255-aaf1-4b5b-ee28-73b1d318d201"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}