![[Pasted image 20251003142302.png]]
- LLM are stateless แปลว่า LLM มันจะไม่จำสิ่งที่เกิดขึ้น มันไม่สามารถจำประวัติอะไรๆ ได้เลย
![[Pasted image 20251003142441.png]]
- สิ่งที่จะเกิดขึ้นก็คือเราจะต้องเอาสิ่งที่เคยตอบโต้กันมาก่อนหน้านี้มากเป็น Prompt เข้าไปให้ LLM
![[Pasted image 20251003142735.png]]
- เรามีหน่วยควาามจำสำหรับ LLM เยอะมาก หนึ่งในนั้นก็คือ ConversationBufferMemory ตัวนี้จะจำทุกอย่างที่เราเคยคุยกัน
- เมื่อเวลาผ่านไปนานเข้าๆ มันจะยิ่งเยอะขึ้นเรื่อยๆ และมันจะแพง
![[Pasted image 20251003142903.png]]
- นอกจากนี้มันก็ยังมี ConversationBufferWindowMemory ที่จะคอยจำเฉพาะ 2 conversation ก่อนหน้า
![[Pasted image 20251003143101.png]]
- แบบถัดไปเรียกว่า ConversationTokenBufferMemory รูปแบบการจำแบบนี้ก็คือมันจะจำเป็นจำนวน Tokens ตามที่เรา set เอาไว้
- วิธีนี้มันเป็นการตัดแบบ limit token ทำให้หลายๆครั้งที่มันตัดบางที่ไม่ได้ใจความ
![[Pasted image 20251003143652.png]]
- วิธีสุดท้ายคือ ConversationSummaryMemory วิธีนี้น่าจะเป็นวิธีที่ดีที่สุก เพราะมันจะ summarize ทุกอย่างแล้วเก็บเป็น context เอาไว้
- แต่ว่าข้อเสียของมันก็คือมันแพงเพราะต้องใช้ token อีกส่สวนในการ summarize ด้วยย