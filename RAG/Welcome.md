![[Pasted image 20250917133105.png]]![[Pasted image 20250917133136.png]]
![[Pasted image 20250917133659.png]]
- มันมีหลายวิธีสำหรับการแก้ไขปัญหา
- บางวิธีคือไล่จากถูก -> แพง
- ==RAG== การทำตัวนี้ไม่ได้แพง
- ==Trained== ตัวนี้อาจจะ Take resource เยอะและจะต้องมีการเตรียมข้อมูล
![[Pasted image 20250917133816.png]]
-  External source เป็นหัวใจของ RAG เป็นเหมือนคลังความรู้ขนาดใหญ่
![[01.png]]
- [[Architecture For Enterprise RAG]]
- ==Embedding== 
	- เป็นเหมือนกับการแปลงสิ่งที่คอมไม่เข้าใจให้สามารถเข้าใจได้ ไม่ว่าจะเป็นข้อความ หรือ รูปภาพ
	- ทำให้เราสามารถเก็บข้อมูลเอาไว้ใน  (Vector) Database ได้  
- ==อันนี้คือ RAG ที่ดีที่จะสามารถส่งมอบได้มันจะมีอยู่ด้วยกัน 17 ส่วนประกอบ==
	- 01_User authentication 
		- มันคือระบบยืนยันตัวจัดการสิทธิการเข้าถึง
		- ปกป้องการเข้าถึง RAG
		- ตัวอย่าง ==AWS recognito (Cloud)==, ==firebase authentication==
	- 02_Input guardrail
		- เป็นการกรองข้อมูลที่ผิดปกติ การห้าม prompt, injection อะไรก็ตามที่มันไม่เหมาะสม
		- ข้อมูลส่วนตัว
		- ตัวอย่าง ==AWS Bedrock guardrail==
	- 03 Query rewriter
		- ตัวที่ใช้ในการปรับปรุงคำถาม 
		- เราจะไม่ใส่คำถามเข้าไปตรงๆ แต่เราจะเอามันมาเขียนคำถามใหม่ก่อน
	- 04 Encoder
		- ตัวแปลงข้อความเป็น Vector
	- 05 Document ingestion
		- เป็นระบบป้อนข้อมูล เป็นการแปลงไฟล์เอกสาร -> ตัดเป็น chunk -> ใส่เข้าไว้ใน Database
	- 06 Storage
		- จะต้องสามารถเก็บข้อมูลหลายๆประเภทได้
			- MongoDB -> Rawtext
			- PieCone -> Vecter
		- สำหรับระบบที่เป็นระดับ Production ใหญ่ๆแล้วเราจำเป็นจะต้องมี database หลายๆ แบบ
		- เวลาที่เราจะต้องเก็บข้อมูลเราจะต้องพิจารณาก่อนว่าเป็นรูปแบบไหน Database ตัวนั้นควรจะเป็นครอบครุมทั้ง Hybrid search และ Vanilla search
			-   เช่น Weaviate / Qdrant
	- 07 HyDE 
		- จะเป็นส่วนที่ LLM synthetic data ขึ้นมาเพื่อให้เอกสารสมบูรณ์
		- ทำให้สามารถค้นหาที่ดีขึ้น
	- 08 Observability
		- การทำ Monitoring
- คำถามของ user จะถูกส่งมาเป็น vector embedding
![[02.png]]
- 7 ปัญหาของการทำ RAG
	- 01 Missing content
		- เวลา user ถามคำถามมาแล้วมันไม่มีข้อมูลมันควรตอบว่าไม่รู้ แต่มันดัน Halusinate ทำให้มีคำตอบมั่วๆ
	- 02 Missed Top Ranked
		- คำตอบมีอยู่ในระบบแต่ว่าเอกสารไม่ได้โดนดึงออกมา
		- เราอาจจะต้องทำ Reranking, เลือกมาสัก 3-5 อัน
	- 03 Not in context
		- เอกสารถูกค้นมาให้แล้วแต่ไม่ถูกส่งให้ LLM 
		- เกิดจากเอกสารเยอะเกินไป เพราะ Token ถูกจำกัด
	- 04 Not Extracted
		- ข้อมูลที่ต้องการมีและได้มีการส่งให้ LLM ด้วยแต่ว่ามันดัน Extracted ออกมาแล้วไม่เจอข้อมูลที่เราต้องการ
		- เกิดจาก context มี noise เยอะเกินไปหรือืขัดแย้งกันเอง
	- 05 Wrong format
		- เราอยากได้ Field JSON แต่ปรากฏว่ามันไม่เหมือนเดิม (Field reference )
		- เราจะต้องระบุให้ดี
	- 06 Incorrect specificity
		- คำตอบที่ได้กว้างหรือละเอียดเกินไปจนไม่ตอบสนองความต้องการของ user 
	- 07 Incomplete
		- ตอบถูกบ้างแต่ตอบมาไม่หมดตอบมาไม่ครบ
		- อย่างเช่นตอบคำถาม ABC แต่ว่าดันตอบคำถามมาแค่ส่วน AB ไม่มี C
		- อาจจะมีการทำ Evaluate เพื่อป้องกันการหลุดของข้อมูล
![[Pasted image 20250917133940.png]]
- เหตุผลที่มีการใช้ Cloud Database เพราะ มันจะเป็นการลดความ bias ของเครื่องได้
- การใช้ Local storage มันดีกว่าไม่ว่าจะเป็นในเรื่องของ
	- การ Implement
	- Cost
- การใช้แบบ Cloud จะดีกว่าในเรื่องของการ scale
- Pinecone มันเป็น Realtime response, แม่นยำ, ไว, scale ง่าย
- ==ในระดับ Production ส่วนมากจะใช้เป็นรูปแบบ Cloud==
![[Pasted image 20250917134013.png]] 
- Database workflow
	1. Create an index
		- การจัดระเบียบข้อมูล Vector ให้ค้นหาได้เร็วขึ้น
		- มีหลายแบบเช่น diant index, semantic search, spark index, hybrid search
	2. Upsert text
		- Update + Insert = Upsert
		- ถ้าหากข้อมูลนั้นมีอยู่แล้วก็จะเป็นการ Update แต่ว่าถ้าหากไม่มีข้อมูลมันจะโดนแปลงเป็น vector และใส่เข้าไป
		- บางครั้งมันมีข้อมูลเดิมอยู่แล้ว ถ้าโดยปกติมันจะต้องทำการแปลงข้อมูลทั้งหมดแต่ว่าตัวนี้มันจะช่วยความสะดวกของเราทำให้มัน Embedding เฉพาะในส่วนของส่วนที่ยังไม่ได้ทำการ Embedding
	3. Search with text
	4. Improve relevance
		- เป็นการทำให้ ผลลัพธ์ออกมาดีที่สุด
		- Filter by metadata เป็นการจำกัดขอบเขตการค้นหาให้แคบลง
		- Rerank result เป็นการเพิ่มความแม่นยำ
		- Lexical search เป็นการค้นหาเชิง Keyword 
![[Pasted image 20250917134714.png]]![[Pasted image 20250917134726.png]]
- "two dogs running" กับ ภาพ เมื่อมีการ Embedding แล้วมันควรที่จะเป็นจุดที่มีความใกล้เคียงกันอยู่บน Vector plane 3D
![[Pasted image 20250918104315.png]]
48:39
- Guardrails มันมีหลาย Service
- AWS ก็มีของเขาเอง
- มันเพื่อป้องกัน Out of domain service
- การมี Guardrails ถ้าหากว่า User ใส่อะไรเข้าไปแล้วติดตรงนี้มันจะเด็งออกเลยโดยที่ไม่เสียเวลาเข้าไป search
- นอกจากนี้ Guardrails สามารถเอาไปเป็น
	- ตัว Activate function
	- router  
![[Pasted image 20250918125214.png]]
- ตัวอย่าง application
- OpenAI มีประสิทธิภาพค่อนข้างดีแต่ว่ามันแพง 
![[Pasted image 20250918130050.png]]
- VisionLLM ณ ปัจจุบันมันเก่งมากเราสามารถที่จะใส่รูปหรืออะไรก็ตามเข้าไปได้ Multimodal ปัจจุบันเก่งขึ้นมากๆ ปกติต้องมีการทำ OCR ทำ Parser  แต่เดิมวิธีการทำจะเป็นแบบบนแต่ตอนนี้กลายเป็นแบบล่างไปแล้ว
- แต่ปัจจุบันแทบจะไม่ต้อง ==ประสิทธิภาพดีกว่า== แต่ค่าใช้จ่ายก็อาจจะสูงกว่า
- Process
	- วิธีเก่า
		- PDF Parser with captioner
			- แปลงข้อมูลที่อยู่ในรูป Plain text ธรรมดาให้สามารถเข้าใช้และทำงานได้ด้วย Computer
			- ข้อเสียคือเวลาทำ PDF parser หรือ OCR เนี้ยข้อมูลที่ได้มันไม่ได้ 100% อาจจะมีหายตกหล่นไปบ้าง ทำให้ขาดบริบทที่สำคัญ
		- OCR
			- OCR จะทำการแปลงรูปภาพไปเป็นตัวอักษร
			- พวกรูปภาพและตารางคือสิ่งที่มักจะมีปัญหา
		- Parsed Doc
			- เอกสารที่อยู่ในรูปที่พร้อมใช้งาน
			- อาจจะอยู่ในรูปแบบ JSON
		- Retrieval model
			- ค้นหาส่วนของข้อมูลที่มีความเกี่ยวค่องที่สุดอาจจะเป็นชิ้นส่วน
			- แล้วส่งไปให้ LLM ตอบ
		- Reranker model
			- เป็นการนำคำตอบที่ได้ไปจัดลำดับใหม่
		- Most Relevant Paragraph
			- หน้าที่เกี่ยวข้องที่สุด เราก็จะมาพิจารณาว่าอะไรเกี่ยวค้องกับคำถามมากที่สุดเวลาที่มีคำถามเข้ามา
	- วิธีใหม่
		- Stack of Documents
		- ColQwen2, DSE + reranker
			- มันสามารถค้นเอกสารที่เกี่ยวข้องได้โดยที่ไม่ต้องผ่านกระบวนการ Parser เลย
			- มันสามารถที่จะ Embedded ข้อมูลทั้งเอกสารและรูปภาพให้มันอยู่ใน vector space เดียวกันได้
			- มันเป็น Multiembedding
			- สามารถวัดความคล้ายคลึงของเอกสารที่ USER ส่งมาได้โดยตรง
			- มันสามารถเข้าใจโครงสร้างเอกสารที่ซับซ่อนรวมถึงเข้าใจภาพได้ดี
			- ข้ามขั้นตอน Parser ไปเพื่อลดความเสี่ยงในการสูญเสียข้อมุล
		- Retrieved document with answer to query
		- VisionLM
			- มันคือ Multimodal LLM มันสามารถประมวลผลได้ทั้ง
				- ข้อความ
				- แผนภูมิ
				- รูปภาพ
			- ทำให้ Model เข้าใจบริบททั้งหมดของเอกสาร
			- ใช้เอกสารที่ค้นมาที่อยู่ในรูปแบบเดิมเพื่อสร้างคำตอบผ่านตัวนี้
- 01:07:24